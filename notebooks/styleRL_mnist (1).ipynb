{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "styleRL_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRgX9_OtfoFZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd1ef8e-ea99-4483-8c91-01a9f1ff2a9a"
      },
      "source": [
        "!gdown \"https://drive.google.com/u/0/uc?id=1FU4_2GEvfWI8dLRsdX-KP5h17-YDEVeS\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1FU4_2GEvfWI8dLRsdX-KP5h17-YDEVeS\n",
            "To: /content/StyledLearningToPaint.zip\n",
            "76.2MB [00:01, 49.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j9MQPEpiGBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24cd782-4e92-4374-b819-4e75ca5ec360"
      },
      "source": [
        "!unzip StyledLearningToPaint.zip "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  StyledLearningToPaint.zip\n",
            "   creating: LearningToPaint/\n",
            "   creating: LearningToPaint/.git/\n",
            "   creating: LearningToPaint/.git/branches/\n",
            "  inflating: LearningToPaint/.git/config  \n",
            "  inflating: LearningToPaint/.git/description  \n",
            " extracting: LearningToPaint/.git/HEAD  \n",
            "   creating: LearningToPaint/.git/hooks/\n",
            "  inflating: LearningToPaint/.git/hooks/applypatch-msg.sample  \n",
            "  inflating: LearningToPaint/.git/hooks/commit-msg.sample  \n",
            "  inflating: LearningToPaint/.git/hooks/post-update.sample  \n",
            "  inflating: LearningToPaint/.git/hooks/pre-applypatch.sample  \n",
            "  inflating: LearningToPaint/.git/hooks/pre-commit.sample  \n",
            "  inflating: LearningToPaint/.git/hooks/pre-push.sample  \n",
            "  inflating: LearningToPaint/.git/hooks/pre-rebase.sample  \n",
            "  inflating: LearningToPaint/.git/hooks/prepare-commit-msg.sample  \n",
            "  inflating: LearningToPaint/.git/hooks/update.sample  \n",
            "  inflating: LearningToPaint/.git/index  \n",
            "   creating: LearningToPaint/.git/info/\n",
            "  inflating: LearningToPaint/.git/info/exclude  \n",
            "   creating: LearningToPaint/.git/logs/\n",
            "  inflating: LearningToPaint/.git/logs/HEAD  \n",
            "   creating: LearningToPaint/.git/logs/refs/\n",
            "   creating: LearningToPaint/.git/logs/refs/heads/\n",
            "  inflating: LearningToPaint/.git/logs/refs/heads/master  \n",
            "   creating: LearningToPaint/.git/logs/refs/remotes/\n",
            "   creating: LearningToPaint/.git/logs/refs/remotes/origin/\n",
            "  inflating: LearningToPaint/.git/logs/refs/remotes/origin/HEAD  \n",
            "   creating: LearningToPaint/.git/objects/\n",
            "   creating: LearningToPaint/.git/objects/info/\n",
            "   creating: LearningToPaint/.git/objects/pack/\n",
            "  inflating: LearningToPaint/.git/objects/pack/pack-5ecbd7e1a64478daf362a898d9960942a731219a.idx  \n",
            "  inflating: LearningToPaint/.git/objects/pack/pack-5ecbd7e1a64478daf362a898d9960942a731219a.pack  \n",
            "  inflating: LearningToPaint/.git/packed-refs  \n",
            "   creating: LearningToPaint/.git/refs/\n",
            "   creating: LearningToPaint/.git/refs/heads/\n",
            "  inflating: LearningToPaint/.git/refs/heads/master  \n",
            "   creating: LearningToPaint/.git/refs/remotes/\n",
            "   creating: LearningToPaint/.git/refs/remotes/origin/\n",
            " extracting: LearningToPaint/.git/refs/remotes/origin/HEAD  \n",
            "   creating: LearningToPaint/.git/refs/tags/\n",
            "  inflating: LearningToPaint/.gitignore  \n",
            "   creating: LearningToPaint/.ipynb_checkpoints/\n",
            "  inflating: LearningToPaint/.ipynb_checkpoints/learningtopaint-checkpoint.ipynb  \n",
            "   creating: LearningToPaint/baseline/\n",
            "   creating: LearningToPaint/baseline/.ipynb_checkpoints/\n",
            "  inflating: LearningToPaint/baseline/.ipynb_checkpoints/env-checkpoint.py  \n",
            "  inflating: LearningToPaint/baseline/.ipynb_checkpoints/test-checkpoint.py  \n",
            "  inflating: LearningToPaint/baseline/.ipynb_checkpoints/train-checkpoint.py  \n",
            "  inflating: LearningToPaint/baseline/.ipynb_checkpoints/train_renderer-checkpoint.py  \n",
            "   creating: LearningToPaint/baseline/DRL/\n",
            "   creating: LearningToPaint/baseline/DRL/.ipynb_checkpoints/\n",
            "  inflating: LearningToPaint/baseline/DRL/.ipynb_checkpoints/actor-checkpoint.py  \n",
            "  inflating: LearningToPaint/baseline/DRL/.ipynb_checkpoints/ddpg-checkpoint.py  \n",
            "  inflating: LearningToPaint/baseline/DRL/.ipynb_checkpoints/evaluator-checkpoint.py  \n",
            "  inflating: LearningToPaint/baseline/DRL/.ipynb_checkpoints/ppo-checkpoint.py  \n",
            "  inflating: LearningToPaint/baseline/DRL/.ipynb_checkpoints/style_transfer-checkpoint.py  \n",
            "  inflating: LearningToPaint/baseline/DRL/.ipynb_checkpoints/wgan-checkpoint.py  \n",
            "  inflating: LearningToPaint/baseline/DRL/actor.py  \n",
            "  inflating: LearningToPaint/baseline/DRL/critic.py  \n",
            "  inflating: LearningToPaint/baseline/DRL/ddpg.py  \n",
            "  inflating: LearningToPaint/baseline/DRL/evaluator.py  \n",
            "  inflating: LearningToPaint/baseline/DRL/fire.jpg  \n",
            "  inflating: LearningToPaint/baseline/DRL/multi.py  \n",
            "  inflating: LearningToPaint/baseline/DRL/ppo.py  \n",
            "  inflating: LearningToPaint/baseline/DRL/rpm.py  \n",
            "  inflating: LearningToPaint/baseline/DRL/style_transfer.py  \n",
            "  inflating: LearningToPaint/baseline/DRL/wgan.py  \n",
            "   creating: LearningToPaint/baseline/DRL/__pycache__/\n",
            "  inflating: LearningToPaint/baseline/DRL/__pycache__/actor.cpython-39.pyc  \n",
            "  inflating: LearningToPaint/baseline/DRL/__pycache__/critic.cpython-39.pyc  \n",
            "  inflating: LearningToPaint/baseline/DRL/__pycache__/ddpg.cpython-39.pyc  \n",
            "  inflating: LearningToPaint/baseline/DRL/__pycache__/evaluator.cpython-39.pyc  \n",
            "  inflating: LearningToPaint/baseline/DRL/__pycache__/multi.cpython-39.pyc  \n",
            "  inflating: LearningToPaint/baseline/DRL/__pycache__/rpm.cpython-39.pyc  \n",
            "  inflating: LearningToPaint/baseline/DRL/__pycache__/wgan.cpython-39.pyc  \n",
            "  inflating: LearningToPaint/baseline/env.py  \n",
            "   creating: LearningToPaint/baseline/Renderer/\n",
            "   creating: LearningToPaint/baseline/Renderer/.ipynb_checkpoints/\n",
            "  inflating: LearningToPaint/baseline/Renderer/.ipynb_checkpoints/model-checkpoint.py  \n",
            "  inflating: LearningToPaint/baseline/Renderer/.ipynb_checkpoints/stroke_gen-checkpoint.py  \n",
            "  inflating: LearningToPaint/baseline/Renderer/model.py  \n",
            "  inflating: LearningToPaint/baseline/Renderer/stroke_gen.py  \n",
            " extracting: LearningToPaint/baseline/Renderer/__init__.py  \n",
            "   creating: LearningToPaint/baseline/Renderer/__pycache__/\n",
            "  inflating: LearningToPaint/baseline/Renderer/__pycache__/model.cpython-39.pyc  \n",
            "  inflating: LearningToPaint/baseline/Renderer/__pycache__/stroke_gen.cpython-39.pyc  \n",
            "  inflating: LearningToPaint/baseline/Renderer/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: LearningToPaint/baseline/test.py  \n",
            "  inflating: LearningToPaint/baseline/train.py  \n",
            "  inflating: LearningToPaint/baseline/train_renderer.py  \n",
            "   creating: LearningToPaint/baseline/utils/\n",
            "  inflating: LearningToPaint/baseline/utils/tensorboard.py  \n",
            "  inflating: LearningToPaint/baseline/utils/util.py  \n",
            "   creating: LearningToPaint/baseline/utils/__pycache__/\n",
            "  inflating: LearningToPaint/baseline/utils/__pycache__/tensorboard.cpython-39.pyc  \n",
            "  inflating: LearningToPaint/baseline/utils/__pycache__/util.cpython-39.pyc  \n",
            "   creating: LearningToPaint/baseline/__pycache__/\n",
            "  inflating: LearningToPaint/baseline/__pycache__/env.cpython-39.pyc  \n",
            "   creating: LearningToPaint/baseline_modelfree/\n",
            "   creating: LearningToPaint/baseline_modelfree/DRL/\n",
            "  inflating: LearningToPaint/baseline_modelfree/DRL/actor.py  \n",
            "  inflating: LearningToPaint/baseline_modelfree/DRL/critic.py  \n",
            "  inflating: LearningToPaint/baseline_modelfree/DRL/ddpg.py  \n",
            "  inflating: LearningToPaint/baseline_modelfree/DRL/evaluator.py  \n",
            "  inflating: LearningToPaint/baseline_modelfree/DRL/multi.py  \n",
            "  inflating: LearningToPaint/baseline_modelfree/DRL/rpm.py  \n",
            "  inflating: LearningToPaint/baseline_modelfree/DRL/wgan.py  \n",
            "  inflating: LearningToPaint/baseline_modelfree/env.py  \n",
            "   creating: LearningToPaint/baseline_modelfree/Renderer/\n",
            "  inflating: LearningToPaint/baseline_modelfree/Renderer/model.py  \n",
            "  inflating: LearningToPaint/baseline_modelfree/Renderer/stroke_gen.py  \n",
            " extracting: LearningToPaint/baseline_modelfree/Renderer/__init__.py  \n",
            "  inflating: LearningToPaint/baseline_modelfree/test.py  \n",
            "  inflating: LearningToPaint/baseline_modelfree/train.py  \n",
            "  inflating: LearningToPaint/baseline_modelfree/train_renderer.py  \n",
            "   creating: LearningToPaint/baseline_modelfree/utils/\n",
            "  inflating: LearningToPaint/baseline_modelfree/utils/tensorboard.py  \n",
            "  inflating: LearningToPaint/baseline_modelfree/utils/util.py  \n",
            "   creating: LearningToPaint/data/\n",
            "   creating: LearningToPaint/data/.ipynb_checkpoints/\n",
            "   creating: LearningToPaint/demo/\n",
            "  inflating: LearningToPaint/demo/deepdream_bird.gif  \n",
            "  inflating: LearningToPaint/demo/deepdream_night.gif  \n",
            "  inflating: LearningToPaint/demo/lisa.gif  \n",
            "  inflating: LearningToPaint/demo/palacemuseum.gif  \n",
            "  inflating: LearningToPaint/demo/sunflower.gif  \n",
            "  inflating: LearningToPaint/demo/sunrise.gif  \n",
            "   creating: LearningToPaint/image/\n",
            "  inflating: LearningToPaint/image/chaoyue.png  \n",
            "  inflating: LearningToPaint/image/degang.png  \n",
            "  inflating: LearningToPaint/image/JayChou.png  \n",
            "  inflating: LearningToPaint/image/Leslie.png  \n",
            "  inflating: LearningToPaint/image/lisa.png  \n",
            "  inflating: LearningToPaint/image/mayun.png  \n",
            "  inflating: LearningToPaint/image/poster.png  \n",
            "  inflating: LearningToPaint/image/test.png  \n",
            "  inflating: LearningToPaint/image/Trump.png  \n",
            "  inflating: LearningToPaint/learningtopaint.ipynb  \n",
            "  inflating: LearningToPaint/LICENSE  \n",
            "   creating: LearningToPaint/log/\n",
            "  inflating: LearningToPaint/log/events.out.tfevents.1608029713.ubuntu  \n",
            "  inflating: LearningToPaint/log/events.out.tfevents.1608029756.ubuntu  \n",
            "  inflating: LearningToPaint/log/events.out.tfevents.1608029808.ubuntu  \n",
            "   creating: LearningToPaint/model/\n",
            "   creating: LearningToPaint/model/Paint-run1/\n",
            "   creating: LearningToPaint/model/Paint-run2/\n",
            "   creating: LearningToPaint/model/Paint-run3/\n",
            "  inflating: LearningToPaint/README.md  \n",
            "  inflating: LearningToPaint/renderer.pkl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp7N29tGkwQs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d78abb07-c9c8-4e2d-c7f5-7011617017c1"
      },
      "source": [
        "cd LearningToPaint//"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LearningToPaint\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnPGj9OFTsV0",
        "outputId": "4cb22290-b11e-4f52-e1e6-496bc2911300"
      },
      "source": [
        "# from google.colab import drive\r\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6sRQjW3ocWQ",
        "outputId": "b2323d3e-8fb1-46ba-c17f-9f85214e85c5"
      },
      "source": [
        "# !ls ../gdrive/MyDrive/RL/ppo_20000_35/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tLearningToPaint  LearningToPaint.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTbhmFyawzhO"
      },
      "source": [
        "Testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0wTTzOEbvps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b66d6a07-ff76-4afe-c872-ffbb8b9663a8"
      },
      "source": [
        "!wget \"https://drive.google.com/uc?export=download&id=1-7dVdjCIZIxh8hHJnGTK-RA1-jL1tor4\" -O ../renderer.pkl"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-20 15:57:10--  https://drive.google.com/uc?export=download&id=1-7dVdjCIZIxh8hHJnGTK-RA1-jL1tor4\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.124.139, 74.125.124.138, 74.125.124.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.124.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0o-58-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/093k392fgbv5kgh7bqk6ben6cfgc8rqh/1608479775000/10102393604162075786/*/1-7dVdjCIZIxh8hHJnGTK-RA1-jL1tor4?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-12-20 15:57:12--  https://doc-0o-58-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/093k392fgbv5kgh7bqk6ben6cfgc8rqh/1608479775000/10102393604162075786/*/1-7dVdjCIZIxh8hHJnGTK-RA1-jL1tor4?e=download\n",
            "Resolving doc-0o-58-docs.googleusercontent.com (doc-0o-58-docs.googleusercontent.com)... 108.177.111.132, 2607:f8b0:4001:c07::84\n",
            "Connecting to doc-0o-58-docs.googleusercontent.com (doc-0o-58-docs.googleusercontent.com)|108.177.111.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘../renderer.pkl’\n",
            "\n",
            "../renderer.pkl         [   <=>              ]  42.12M  68.1MB/s    in 0.6s    \n",
            "\n",
            "2020-12-20 15:57:13 (68.1 MB/s) - ‘../renderer.pkl’ saved [44165821]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfd53Hw2cfaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ed897d3-48d4-4291-eddd-f03326f55640"
      },
      "source": [
        "!wget \"https://drive.google.com/uc?export=download&id=1a3vpKgjCVXHON4P7wodqhCgCMPgg1KeR\" -O actor.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-18 15:51:41--  https://drive.google.com/uc?export=download&id=1a3vpKgjCVXHON4P7wodqhCgCMPgg1KeR\n",
            "Resolving drive.google.com (drive.google.com)... 172.217.13.78, 2607:f8b0:4004:806::200e\n",
            "Connecting to drive.google.com (drive.google.com)|172.217.13.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0c-58-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ngl566kimcn5a8it3119231hce4k8sfs/1608306675000/10102393604162075786/*/1a3vpKgjCVXHON4P7wodqhCgCMPgg1KeR?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-12-18 15:51:44--  https://doc-0c-58-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ngl566kimcn5a8it3119231hce4k8sfs/1608306675000/10102393604162075786/*/1a3vpKgjCVXHON4P7wodqhCgCMPgg1KeR?e=download\n",
            "Resolving doc-0c-58-docs.googleusercontent.com (doc-0c-58-docs.googleusercontent.com)... 172.217.13.65, 2607:f8b0:4004:808::2001\n",
            "Connecting to doc-0c-58-docs.googleusercontent.com (doc-0c-58-docs.googleusercontent.com)|172.217.13.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘actor.pkl’\n",
            "\n",
            "actor.pkl               [     <=>            ]  42.82M  30.0MB/s    in 1.4s    \n",
            "\n",
            "2020-12-18 15:51:45 (30.0 MB/s) - ‘actor.pkl’ saved [44898539]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZpb3_3QiMZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0973f2a-fbe7-437d-bc28-50e3112b2231"
      },
      "source": [
        "!wget -U NoSuchBrowser/1.0 -O image/test.png https://raw.githubusercontent.com/hzwer/LearningToPaint/master/image/Trump.png"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-20 12:20:25--  https://raw.githubusercontent.com/hzwer/LearningToPaint/master/image/Trump.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36916 (36K) [image/png]\n",
            "Saving to: ‘image/test.png’\n",
            "\n",
            "\rimage/test.png        0%[                    ]       0  --.-KB/s               \rimage/test.png      100%[===================>]  36.05K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-12-20 12:20:25 (68.7 MB/s) - ‘image/test.png’ saved [36916/36916]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brX4ZlQoc9ss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f49f264-473b-48ed-e754-9005726269cd"
      },
      "source": [
        "!python3 baseline/test.py --max_step=30 --actor=/content/LearningToPaint/model/Paint-run6/actor.pkl --renderer=/content/LearningToPaint/renderer.pkl --img=image/test.png --divide=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘output’: File exists\n",
            "canvas step 0, L2Loss = 0.10400687158107758\n",
            "canvas step 1, L2Loss = 0.03621567040681839\n",
            "canvas step 2, L2Loss = 0.030137021094560623\n",
            "canvas step 3, L2Loss = 0.02856222167611122\n",
            "canvas step 4, L2Loss = 0.027879228815436363\n",
            "canvas step 5, L2Loss = 0.02784457430243492\n",
            "canvas step 6, L2Loss = 0.027967272326350212\n",
            "canvas step 7, L2Loss = 0.028144046664237976\n",
            "canvas step 8, L2Loss = 0.02838176116347313\n",
            "canvas step 9, L2Loss = 0.028647005558013916\n",
            "canvas step 10, L2Loss = 0.028911057859659195\n",
            "canvas step 11, L2Loss = 0.029168684035539627\n",
            "canvas step 12, L2Loss = 0.029418451711535454\n",
            "canvas step 13, L2Loss = 0.02965819463133812\n",
            "canvas step 14, L2Loss = 0.02988756075501442\n",
            "canvas step 15, L2Loss = 0.03010394796729088\n",
            "canvas step 16, L2Loss = 0.030308451503515244\n",
            "canvas step 17, L2Loss = 0.030503101646900177\n",
            "canvas step 18, L2Loss = 0.03068985603749752\n",
            "canvas step 19, L2Loss = 0.03086736425757408\n",
            "canvas step 20, L2Loss = 0.03103446029126644\n",
            "canvas step 21, L2Loss = 0.03119180165231228\n",
            "canvas step 22, L2Loss = 0.031339455395936966\n",
            "canvas step 23, L2Loss = 0.03147783875465393\n",
            "canvas step 24, L2Loss = 0.03160802274942398\n",
            "canvas step 25, L2Loss = 0.03173064440488815\n",
            "canvas step 26, L2Loss = 0.0318463034927845\n",
            "canvas step 27, L2Loss = 0.031955596059560776\n",
            "canvas step 28, L2Loss = 0.03205907344818115\n",
            "canvas step 29, L2Loss = 0.03215679153800011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLM4U6F0_yjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "416d88f3-9295-4b83-b725-56bdccb2b9e5"
      },
      "source": [
        "!ffmpeg -r 30 -f image2 -i output/generated%d.png -s 512x512 -c:v libx264 -pix_fmt yuv420p video2.mp4 -q:v 0 -q:a 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "\u001b[0;33mTrailing options were found on the commandline.\n",
            "\u001b[0mInput #0, image2, from 'output/generated%d.png':\n",
            "  Duration: 00:00:05.00, start: 0.000000, bitrate: N/A\n",
            "    Stream #0:0: Video: png, rgb24(pc), 128x127, 30 fps, 30 tbr, 30 tbn, 30 tbc\n",
            "File 'video2.mp4' already exists. Overwrite ? [y/N] y\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mprofile High, level 3.0\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'video2.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 512x512, q=-1--1, 30 fps, 15360 tbn, 30 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "frame=  150 fps= 81 q=-1.0 Lsize=     123kB time=00:00:04.90 bitrate= 205.7kbits/s speed=2.65x    \n",
            "video:120kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.090205%\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mframe I:1     Avg QP:19.59  size:  1259\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mframe P:49    Avg QP:21.20  size:  1903\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mframe B:100   Avg QP:23.12  size:   282\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mconsecutive B-frames:  2.7% 21.3% 12.0% 64.0%\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mmb I  I16..4:  8.8% 91.1%  0.1%\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mmb P  I16..4:  5.7% 12.9%  0.1%  P16..4: 41.1%  4.3%  2.1%  0.0%  0.0%    skip:33.8%\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mmb B  I16..4:  0.2%  0.3%  0.0%  B16..8: 15.9%  0.3%  0.0%  direct: 0.3%  skip:83.0%  L0:57.1% L1:41.8% BI: 1.0%\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0m8x8 transform intra:70.8% inter:98.6%\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mcoded y,uvDC,uvAC intra: 21.5% 24.3% 1.4% inter: 3.9% 7.1% 0.0%\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mi16 v,h,dc,p: 26% 20%  8% 46%\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 28% 16% 30%  3%  6%  6%  5%  4%  2%\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 38% 15% 24%  3%  6%  6%  4%  3%  2%\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mi8c dc,h,v,p: 70% 12% 16%  1%\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mWeighted P-Frames: Y:24.5% UV:12.2%\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mref P L0: 38.4%  9.1% 41.2%  6.7%  4.5%\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mref B L0: 62.7% 22.7% 14.6%\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mref B L1: 96.8%  3.2%\n",
            "\u001b[1;36m[libx264 @ 0x55806adb1e00] \u001b[0mkb/s:196.31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2mAkgRjwwuf"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-p0NhqyTqO_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d421972-c385-4543-9a31-77a90b1f1b75"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNzRRtG0pZKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1021c2c-94ef-49af-c9ab-8bedb298da5c"
      },
      "source": [
        "!rm output/*"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'output/*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXAV9RwkTwKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1492eb5-fbba-4d9c-8fa1-9c87a960aa46"
      },
      "source": [
        "cd data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LearningToPaint/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzZUVjdrET2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9779021e-290b-4318-ea95-ddeee891528e"
      },
      "source": [
        "!wget https://github.com/myleott/mnist_png/raw/master/mnist_png.tar.gz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-20 12:38:51--  https://github.com/myleott/mnist_png/raw/master/mnist_png.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/myleott/mnist_png/master/mnist_png.tar.gz [following]\n",
            "--2020-12-20 12:38:51--  https://raw.githubusercontent.com/myleott/mnist_png/master/mnist_png.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15683414 (15M) [application/octet-stream]\n",
            "Saving to: ‘mnist_png.tar.gz’\n",
            "\n",
            "mnist_png.tar.gz    100%[===================>]  14.96M  47.8MB/s    in 0.3s    \n",
            "\n",
            "2020-12-20 12:38:52 (47.8 MB/s) - ‘mnist_png.tar.gz’ saved [15683414/15683414]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgguAW3eETVd"
      },
      "source": [
        "!tar -xvf mnist_png.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14Dwa-jJJ6BF"
      },
      "source": [
        "mkdir mnist"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx-GC6ojJ9tD",
        "outputId": "4ead1f12-11b6-4d6e-bdba-d25c9be99c31"
      },
      "source": [
        "cd mnist/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LearningToPaint/data/mnist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dSb6i61Kcn6"
      },
      "source": [
        "mkdir training"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJhuw9X4KdM5"
      },
      "source": [
        "mkdir testing"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb6-jarSKdg5"
      },
      "source": [
        "import os\r\n",
        "import shutil\r\n",
        "src = '/content/LearningToPaint/data/mnist_png/training/'\r\n",
        "curr = 0\r\n",
        "d = {}\r\n",
        "for label in range(10):\r\n",
        "  src_files = os.listdir(src+str(label)+'/')\r\n",
        "  src_path = src + str(label)\r\n",
        "  for file_name in src_files:\r\n",
        "      full_file_name = os.path.join(src_path, file_name)\r\n",
        "      d[file_name] = 1\r\n",
        "      if os.path.isfile(full_file_name):\r\n",
        "          shutil.copy(full_file_name, '/content/LearningToPaint/data/mnist/training/')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyPaj1r2Kd0R"
      },
      "source": [
        "import os\r\n",
        "import shutil\r\n",
        "src = '/content/LearningToPaint/data/mnist_png/testing/'\r\n",
        "curr = 0\r\n",
        "d1 = {}\r\n",
        "for label in range(10):\r\n",
        "  src_files = os.listdir(src+str(label)+'/')\r\n",
        "  src_path = src + str(label)\r\n",
        "  for file_name in src_files:\r\n",
        "      full_file_name = os.path.join(src_path, file_name)\r\n",
        "      d1[full_file_name] = 1\r\n",
        "      shutil.copy(full_file_name, '/content/LearningToPaint/data/mnist/testing/')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb8qDTuHKski",
        "outputId": "6b9974fe-47a3-48a0-d290-6ee34ab52b60"
      },
      "source": [
        "print('Train Samples:', len(d))\r\n",
        "print('Test Samples:', len(d1))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Samples: 60000\n",
            "Test Samples: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6mVpjvBvzrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6adc83e-aa07-41d6-eb54-9fdb1ba80c80"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LearningToPaint\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCE6VeEAKs_r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZWjNmD23gKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb7b013-d59e-4faa-b56f-4e21623f481c"
      },
      "source": [
        "!pip install tensorboardX v\r\n",
        "!pip install scipy==1.0.0"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\r\u001b[K     |█                               | 10kB 22.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 21.1MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 235kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 256kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 276kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 296kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 307kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 7.0MB/s \n",
            "\u001b[?25hCollecting v\n",
            "  Downloading https://files.pythonhosted.org/packages/63/65/dcbe0c03f51e7c7e675df4d4f106145f8577990d23395e77e33104d2168b/v-0.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.19.4)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (50.3.2)\n",
            "Installing collected packages: tensorboardX, v\n",
            "Successfully installed tensorboardX-2.1 v-0.0.0\n",
            "Collecting scipy==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/5e/caa01ba7be11600b6a9d39265440d7b3be3d69206da887c42bef049521f2/scipy-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (50.0MB)\n",
            "\u001b[K     |████████████████████████████████| 50.0MB 65kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.0.0) (1.19.4)\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.31 has requirement scipy>=1.1.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed scipy-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehnzhWn9GG4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec0c9e42-2cb2-485f-f201-a769dc572ee9"
      },
      "source": [
        "%%writefile baseline/env.py\n",
        "import sys\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "from DRL.ddpg import decode\n",
        "from utils.util import *\n",
        "from PIL import Image\n",
        "from torchvision import transforms, utils\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "aug = transforms.Compose(\n",
        "            [transforms.ToPILImage(),\n",
        "             transforms.RandomHorizontalFlip(),\n",
        "             ])\n",
        "\n",
        "width = 128\n",
        "convas_area = width * width\n",
        "\n",
        "img_train = []\n",
        "img_test = []\n",
        "train_num = 0\n",
        "test_num = 0\n",
        "\n",
        "class Paint:\n",
        "    def __init__(self, batch_size, max_step):\n",
        "        self.batch_size = batch_size\n",
        "        self.max_step = max_step\n",
        "        self.action_space = (13)\n",
        "        self.observation_space = (self.batch_size, width, width, 7)\n",
        "        self.test = False\n",
        "        \n",
        "    def load_data(self):\n",
        "        # CelebA\n",
        "        global train_num, test_num\n",
        "        for i in range(60000):\n",
        "            img_id = str(i)\n",
        "            try:\n",
        "                img = cv2.imread('./data/mnist/training/' + img_id + '.png', cv2.IMREAD_UNCHANGED)\n",
        "                img = cv2.resize(img, (width, width))\n",
        "                train_num += 1\n",
        "                img_train.append(img)\n",
        "            finally:\n",
        "                if (i + 1) % 10000 == 0:                    \n",
        "                    print('loaded {} images (Training)'.format(i + 1))\n",
        "\n",
        "        for i in range(10000):\n",
        "            img_id = str(i)\n",
        "            try:\n",
        "                img = cv2.imread('./data/mnist/testing/' + img_id + '.png', cv2.IMREAD_UNCHANGED)\n",
        "                img = cv2.resize(img, (width, width))\n",
        "                test_num += 1\n",
        "                img_test.append(img)\n",
        "            finally:\n",
        "                if (i + 1) % 5000 == 0:                    \n",
        "                    print('loaded {} images (Testing)'.format(i + 1))\n",
        "        print('finish loading data, {} training images, {} testing images'.format(str(train_num), str(test_num)))\n",
        "        \n",
        "    def pre_data(self, id, test):\n",
        "        if test:\n",
        "            img = img_test[id]\n",
        "        else:\n",
        "            img = img_train[id]\n",
        "        if not test:\n",
        "            img = aug(img)\n",
        "        img = np.asarray(img)\n",
        "        img = img.reshape((128,128,1))\n",
        "        return np.transpose(img, (2, 0, 1))\n",
        "    \n",
        "    def reset(self, test=False, begin_num=False):\n",
        "        self.test = test\n",
        "        self.imgid = [0] * self.batch_size\n",
        "        self.gt = torch.zeros([self.batch_size, 3, width, width], dtype=torch.uint8).to(device)\n",
        "        for i in range(self.batch_size):\n",
        "            if test:\n",
        "                id = (i + begin_num)  % test_num\n",
        "            else:\n",
        "                id = np.random.randint(train_num)\n",
        "            self.imgid[i] = id\n",
        "            self.gt[i] = torch.tensor(self.pre_data(id, test))\n",
        "        self.tot_reward = ((self.gt.float() / 255) ** 2).mean(1).mean(1).mean(1)\n",
        "        self.stepnum = 0\n",
        "        self.canvas = torch.zeros([self.batch_size, 3, width, width], dtype=torch.uint8).to(device)\n",
        "        self.lastdis = self.ini_dis = self.cal_dis()\n",
        "        return self.observation()\n",
        "    \n",
        "    def observation(self):\n",
        "        # canvas B * 3 * width * width\n",
        "        # gt B * 3 * width * width\n",
        "        # T B * 1 * width * width\n",
        "        ob = []\n",
        "        T = torch.ones([self.batch_size, 1, width, width], dtype=torch.uint8) * self.stepnum\n",
        "        return torch.cat((self.canvas, self.gt, T.to(device)), 1) # canvas, img, T\n",
        "\n",
        "    def cal_trans(self, s, t):\n",
        "        return (s.transpose(0, 3) * t).transpose(0, 3)\n",
        "    \n",
        "    def step(self, action):\n",
        "        self.canvas = (decode(action, self.canvas.float() / 255) * 255).byte()\n",
        "        self.stepnum += 1\n",
        "        ob = self.observation()\n",
        "        done = (self.stepnum == self.max_step)\n",
        "        reward = self.cal_reward() # np.array([0.] * self.batch_size)\n",
        "        return ob.detach(), reward, np.array([done] * self.batch_size), None\n",
        "\n",
        "    def cal_dis(self):\n",
        "        return (((self.canvas.float() - self.gt.float()) / 255) ** 2).mean(1).mean(1).mean(1)\n",
        "    \n",
        "    def cal_reward(self):\n",
        "        dis = self.cal_dis()\n",
        "        reward = (self.lastdis - dis) / (self.ini_dis + 1e-8)\n",
        "        self.lastdis = dis\n",
        "        return to_numpy(reward)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting baseline/env.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9Xa5dFQzEyh"
      },
      "source": [
        "!rm -r ../train_log/*"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kwVmo6yv1w3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f46b955-5db4-40dc-d213-5d4bb7269987"
      },
      "source": [
        "!python3 baseline/train.py --max_step=6 --debug --batch_size=16 --train_times=20000"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./model’: File exists\n",
            "loaded 10000 images (Training)\n",
            "loaded 20000 images (Training)\n",
            "loaded 30000 images (Training)\n",
            "loaded 40000 images (Training)\n",
            "loaded 50000 images (Training)\n",
            "loaded 60000 images (Training)\n",
            "loaded 5000 images (Testing)\n",
            "loaded 10000 images (Testing)\n",
            "finish loading data, 60000 training images, 10000 testing images\n",
            "observation_space (96, 128, 128, 7) action_space 13\n",
            "/content/LearningToPaint/baseline/env.py:82: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  self.gt[i] = torch.tensor(self.pre_data(id, test))\n",
            "/content/LearningToPaint/baseline/DRL/ddpg.py:157: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  s0 = torch.tensor(self.state, device='cpu')\n",
            "/content/LearningToPaint/baseline/DRL/ddpg.py:160: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  s1 = torch.tensor(state, device='cpu')\n",
            "\u001b[98m #0: steps:6 interval_time:1.04 train_time:0.00\u001b[00m\n",
            "\u001b[98m #1: steps:12 interval_time:0.52 train_time:0.00\u001b[00m\n",
            "\u001b[98m #2: steps:18 interval_time:0.52 train_time:0.00\u001b[00m\n",
            "\u001b[98m #3: steps:24 interval_time:0.56 train_time:0.00\u001b[00m\n",
            "\u001b[98m #4: steps:30 interval_time:0.52 train_time:0.00\u001b[00m\n",
            "\u001b[98m #5: steps:36 interval_time:0.51 train_time:0.00\u001b[00m\n",
            "\u001b[98m #6: steps:42 interval_time:0.52 train_time:0.00\u001b[00m\n",
            "\u001b[98m #7: steps:48 interval_time:0.53 train_time:0.00\u001b[00m\n",
            "\u001b[98m #8: steps:54 interval_time:0.50 train_time:0.00\u001b[00m\n",
            "\u001b[98m #9: steps:60 interval_time:0.48 train_time:0.00\u001b[00m\n",
            "\u001b[98m #10: steps:66 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #11: steps:72 interval_time:0.48 train_time:0.00\u001b[00m\n",
            "\u001b[98m #12: steps:78 interval_time:0.48 train_time:0.00\u001b[00m\n",
            "\u001b[98m #13: steps:84 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #14: steps:90 interval_time:0.48 train_time:0.00\u001b[00m\n",
            "\u001b[98m #15: steps:96 interval_time:0.48 train_time:0.00\u001b[00m\n",
            "\u001b[98m #16: steps:102 interval_time:0.48 train_time:0.00\u001b[00m\n",
            "\u001b[98m #17: steps:108 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #18: steps:114 interval_time:0.49 train_time:0.00\u001b[00m\n",
            "\u001b[98m #19: steps:120 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #20: steps:126 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #21: steps:132 interval_time:0.48 train_time:0.00\u001b[00m\n",
            "\u001b[98m #22: steps:138 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #23: steps:144 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #24: steps:150 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #25: steps:156 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #26: steps:162 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #27: steps:168 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #28: steps:174 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #29: steps:180 interval_time:0.48 train_time:0.00\u001b[00m\n",
            "\u001b[98m #30: steps:186 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #31: steps:192 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #32: steps:198 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #33: steps:204 interval_time:0.48 train_time:0.00\u001b[00m\n",
            "\u001b[98m #34: steps:210 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #35: steps:216 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #36: steps:222 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #37: steps:228 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #38: steps:234 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #39: steps:240 interval_time:0.48 train_time:0.00\u001b[00m\n",
            "\u001b[98m #40: steps:246 interval_time:0.49 train_time:0.00\u001b[00m\n",
            "\u001b[98m #41: steps:252 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #42: steps:258 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #43: steps:264 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #44: steps:270 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #45: steps:276 interval_time:0.48 train_time:0.00\u001b[00m\n",
            "\u001b[98m #46: steps:282 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #47: steps:288 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #48: steps:294 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #49: steps:300 interval_time:0.48 train_time:0.00\u001b[00m\n",
            "\u001b[98m #50: steps:306 interval_time:0.48 train_time:0.00\u001b[00m\n",
            "\u001b[98m #51: steps:312 interval_time:0.49 train_time:0.00\u001b[00m\n",
            "\u001b[98m #52: steps:318 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #53: steps:324 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #54: steps:330 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #55: steps:336 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #56: steps:342 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #57: steps:348 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #58: steps:354 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #59: steps:360 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #60: steps:366 interval_time:0.47 train_time:0.00\u001b[00m\n",
            "\u001b[98m #61: steps:372 interval_time:0.48 train_time:0.00\u001b[00m\n",
            "\u001b[98m #62: steps:378 interval_time:0.49 train_time:0.00\u001b[00m\n",
            "\u001b[98m #63: steps:384 interval_time:0.48 train_time:0.00\u001b[00m\n",
            "\u001b[98m #64: steps:390 interval_time:0.48 train_time:0.00\u001b[00m\n",
            "\u001b[98m #65: steps:396 interval_time:0.48 train_time:0.00\u001b[00m\n",
            "\u001b[98m #66: steps:402 interval_time:0.47 train_time:4.46\u001b[00m\n",
            "\u001b[98m #67: steps:408 interval_time:0.48 train_time:3.92\u001b[00m\n",
            "\u001b[98m #68: steps:414 interval_time:0.47 train_time:3.93\u001b[00m\n",
            "\u001b[98m #69: steps:420 interval_time:0.48 train_time:3.93\u001b[00m\n",
            "\u001b[98m #70: steps:426 interval_time:0.48 train_time:3.92\u001b[00m\n",
            "\u001b[98m #71: steps:432 interval_time:0.47 train_time:3.92\u001b[00m\n",
            "\u001b[98m #72: steps:438 interval_time:0.47 train_time:3.91\u001b[00m\n",
            "\u001b[98m #73: steps:444 interval_time:0.47 train_time:3.93\u001b[00m\n",
            "\u001b[98m #74: steps:450 interval_time:0.48 train_time:3.93\u001b[00m\n",
            "\u001b[98m #75: steps:456 interval_time:0.47 train_time:3.93\u001b[00m\n",
            "\u001b[98m #76: steps:462 interval_time:0.47 train_time:3.92\u001b[00m\n",
            "\u001b[98m #77: steps:468 interval_time:0.47 train_time:3.94\u001b[00m\n",
            "\u001b[98m #78: steps:474 interval_time:0.47 train_time:3.93\u001b[00m\n",
            "\u001b[98m #79: steps:480 interval_time:0.47 train_time:3.94\u001b[00m\n",
            "\u001b[98m #80: steps:486 interval_time:0.47 train_time:3.94\u001b[00m\n",
            "\u001b[98m #81: steps:492 interval_time:0.47 train_time:3.95\u001b[00m\n",
            "\u001b[98m #82: steps:498 interval_time:0.47 train_time:3.94\u001b[00m\n",
            "\u001b[98m #83: steps:504 interval_time:0.48 train_time:3.95\u001b[00m\n",
            "\u001b[98m #84: steps:510 interval_time:0.47 train_time:3.94\u001b[00m\n",
            "\u001b[98m #85: steps:516 interval_time:0.47 train_time:3.95\u001b[00m\n",
            "\u001b[98m #86: steps:522 interval_time:0.47 train_time:3.93\u001b[00m\n",
            "\u001b[98m #87: steps:528 interval_time:0.48 train_time:3.94\u001b[00m\n",
            "\u001b[98m #88: steps:534 interval_time:0.47 train_time:3.93\u001b[00m\n",
            "\u001b[98m #89: steps:540 interval_time:0.47 train_time:3.95\u001b[00m\n",
            "\u001b[98m #90: steps:546 interval_time:0.47 train_time:3.95\u001b[00m\n",
            "\u001b[98m #91: steps:552 interval_time:0.47 train_time:3.95\u001b[00m\n",
            "\u001b[98m #92: steps:558 interval_time:0.47 train_time:3.95\u001b[00m\n",
            "\u001b[98m #93: steps:564 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #94: steps:570 interval_time:0.48 train_time:3.94\u001b[00m\n",
            "\u001b[98m #95: steps:576 interval_time:0.47 train_time:3.95\u001b[00m\n",
            "\u001b[98m #96: steps:582 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #97: steps:588 interval_time:0.47 train_time:3.95\u001b[00m\n",
            "\u001b[98m #98: steps:594 interval_time:0.47 train_time:3.95\u001b[00m\n",
            "\u001b[98m #99: steps:600 interval_time:0.47 train_time:3.95\u001b[00m\n",
            "\u001b[91m Step_0000605: mean_reward:-4.986 mean_dist:0.464 var_dist:0.001\u001b[00m\n",
            "\u001b[98m #100: steps:606 interval_time:3.42 train_time:3.96\u001b[00m\n",
            "\u001b[98m #101: steps:612 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #102: steps:618 interval_time:0.48 train_time:3.95\u001b[00m\n",
            "\u001b[98m #103: steps:624 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #104: steps:630 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #105: steps:636 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #106: steps:642 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #107: steps:648 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #108: steps:654 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #109: steps:660 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #110: steps:666 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #111: steps:672 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #112: steps:678 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #113: steps:684 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #114: steps:690 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #115: steps:696 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #116: steps:702 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #117: steps:708 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #118: steps:714 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #119: steps:720 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #120: steps:726 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #121: steps:732 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #122: steps:738 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #123: steps:744 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #124: steps:750 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #125: steps:756 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #126: steps:762 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #127: steps:768 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #128: steps:774 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #129: steps:780 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #130: steps:786 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #131: steps:792 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #132: steps:798 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #133: steps:804 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #134: steps:810 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #135: steps:816 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #136: steps:822 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #137: steps:828 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #138: steps:834 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #139: steps:840 interval_time:0.49 train_time:3.98\u001b[00m\n",
            "\u001b[98m #140: steps:846 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #141: steps:852 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #142: steps:858 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #143: steps:864 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #144: steps:870 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #145: steps:876 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #146: steps:882 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #147: steps:888 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #148: steps:894 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #149: steps:900 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0000905: mean_reward:-0.065 mean_dist:0.098 var_dist:0.001\u001b[00m\n",
            "\u001b[98m #150: steps:906 interval_time:3.37 train_time:3.97\u001b[00m\n",
            "\u001b[98m #151: steps:912 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #152: steps:918 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #153: steps:924 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #154: steps:930 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #155: steps:936 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #156: steps:942 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #157: steps:948 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #158: steps:954 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #159: steps:960 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #160: steps:966 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #161: steps:972 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #162: steps:978 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #163: steps:984 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #164: steps:990 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #165: steps:996 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #166: steps:1002 interval_time:0.48 train_time:3.96\u001b[00m\n",
            "\u001b[98m #167: steps:1008 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #168: steps:1014 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #169: steps:1020 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #170: steps:1026 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #171: steps:1032 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #172: steps:1038 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #173: steps:1044 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #174: steps:1050 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #175: steps:1056 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #176: steps:1062 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #177: steps:1068 interval_time:0.49 train_time:3.97\u001b[00m\n",
            "\u001b[98m #178: steps:1074 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #179: steps:1080 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #180: steps:1086 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #181: steps:1092 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #182: steps:1098 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #183: steps:1104 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #184: steps:1110 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #185: steps:1116 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #186: steps:1122 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #187: steps:1128 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #188: steps:1134 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #189: steps:1140 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #190: steps:1146 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #191: steps:1152 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #192: steps:1158 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #193: steps:1164 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #194: steps:1170 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #195: steps:1176 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #196: steps:1182 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #197: steps:1188 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #198: steps:1194 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #199: steps:1200 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0001205: mean_reward:0.217 mean_dist:0.071 var_dist:0.001\u001b[00m\n",
            "\u001b[98m #200: steps:1206 interval_time:3.50 train_time:3.98\u001b[00m\n",
            "\u001b[98m #201: steps:1212 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #202: steps:1218 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #203: steps:1224 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #204: steps:1230 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #205: steps:1236 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #206: steps:1242 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #207: steps:1248 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #208: steps:1254 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #209: steps:1260 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #210: steps:1266 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #211: steps:1272 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #212: steps:1278 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #213: steps:1284 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #214: steps:1290 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #215: steps:1296 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #216: steps:1302 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #217: steps:1308 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #218: steps:1314 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #219: steps:1320 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #220: steps:1326 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #221: steps:1332 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #222: steps:1338 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #223: steps:1344 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #224: steps:1350 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #225: steps:1356 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #226: steps:1362 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #227: steps:1368 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #228: steps:1374 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #229: steps:1380 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #230: steps:1386 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #231: steps:1392 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #232: steps:1398 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #233: steps:1404 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #234: steps:1410 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #235: steps:1416 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #236: steps:1422 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #237: steps:1428 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #238: steps:1434 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #239: steps:1440 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #240: steps:1446 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #241: steps:1452 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #242: steps:1458 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #243: steps:1464 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #244: steps:1470 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #245: steps:1476 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #246: steps:1482 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #247: steps:1488 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #248: steps:1494 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #249: steps:1500 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[91m Step_0001505: mean_reward:-0.433 mean_dist:0.122 var_dist:0.002\u001b[00m\n",
            "\u001b[98m #250: steps:1506 interval_time:3.61 train_time:3.97\u001b[00m\n",
            "\u001b[98m #251: steps:1512 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #252: steps:1518 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #253: steps:1524 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #254: steps:1530 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #255: steps:1536 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #256: steps:1542 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #257: steps:1548 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #258: steps:1554 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #259: steps:1560 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #260: steps:1566 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #261: steps:1572 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #262: steps:1578 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #263: steps:1584 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #264: steps:1590 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #265: steps:1596 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #266: steps:1602 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #267: steps:1608 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #268: steps:1614 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #269: steps:1620 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #270: steps:1626 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #271: steps:1632 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #272: steps:1638 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #273: steps:1644 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #274: steps:1650 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #275: steps:1656 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #276: steps:1662 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #277: steps:1668 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #278: steps:1674 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #279: steps:1680 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #280: steps:1686 interval_time:0.49 train_time:3.98\u001b[00m\n",
            "\u001b[98m #281: steps:1692 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #282: steps:1698 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #283: steps:1704 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #284: steps:1710 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #285: steps:1716 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #286: steps:1722 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #287: steps:1728 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #288: steps:1734 interval_time:0.49 train_time:3.99\u001b[00m\n",
            "\u001b[98m #289: steps:1740 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #290: steps:1746 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #291: steps:1752 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #292: steps:1758 interval_time:0.48 train_time:3.96\u001b[00m\n",
            "\u001b[98m #293: steps:1764 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #294: steps:1770 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #295: steps:1776 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #296: steps:1782 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #297: steps:1788 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #298: steps:1794 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #299: steps:1800 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0001805: mean_reward:-5.914 mean_dist:0.541 var_dist:0.001\u001b[00m\n",
            "\u001b[98m #300: steps:1806 interval_time:3.53 train_time:3.97\u001b[00m\n",
            "\u001b[98m #301: steps:1812 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #302: steps:1818 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #303: steps:1824 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #304: steps:1830 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #305: steps:1836 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #306: steps:1842 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #307: steps:1848 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #308: steps:1854 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #309: steps:1860 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #310: steps:1866 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #311: steps:1872 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #312: steps:1878 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #313: steps:1884 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #314: steps:1890 interval_time:0.48 train_time:3.96\u001b[00m\n",
            "\u001b[98m #315: steps:1896 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #316: steps:1902 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #317: steps:1908 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #318: steps:1914 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #319: steps:1920 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #320: steps:1926 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #321: steps:1932 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #322: steps:1938 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #323: steps:1944 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #324: steps:1950 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #325: steps:1956 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #326: steps:1962 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #327: steps:1968 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #328: steps:1974 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #329: steps:1980 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #330: steps:1986 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #331: steps:1992 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #332: steps:1998 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #333: steps:2004 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #334: steps:2010 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #335: steps:2016 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #336: steps:2022 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #337: steps:2028 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #338: steps:2034 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #339: steps:2040 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #340: steps:2046 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #341: steps:2052 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #342: steps:2058 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #343: steps:2064 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #344: steps:2070 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #345: steps:2076 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #346: steps:2082 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #347: steps:2088 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #348: steps:2094 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #349: steps:2100 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[91m Step_0002105: mean_reward:-1.636 mean_dist:0.211 var_dist:0.001\u001b[00m\n",
            "\u001b[98m #350: steps:2106 interval_time:3.38 train_time:3.97\u001b[00m\n",
            "\u001b[98m #351: steps:2112 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #352: steps:2118 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #353: steps:2124 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #354: steps:2130 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #355: steps:2136 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #356: steps:2142 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #357: steps:2148 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #358: steps:2154 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #359: steps:2160 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #360: steps:2166 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #361: steps:2172 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #362: steps:2178 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #363: steps:2184 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #364: steps:2190 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #365: steps:2196 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #366: steps:2202 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #367: steps:2208 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #368: steps:2214 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #369: steps:2220 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #370: steps:2226 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #371: steps:2232 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #372: steps:2238 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #373: steps:2244 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #374: steps:2250 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #375: steps:2256 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #376: steps:2262 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #377: steps:2268 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #378: steps:2274 interval_time:0.48 train_time:3.96\u001b[00m\n",
            "\u001b[98m #379: steps:2280 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #380: steps:2286 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #381: steps:2292 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #382: steps:2298 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #383: steps:2304 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #384: steps:2310 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #385: steps:2316 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #386: steps:2322 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #387: steps:2328 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #388: steps:2334 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #389: steps:2340 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #390: steps:2346 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #391: steps:2352 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #392: steps:2358 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #393: steps:2364 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #394: steps:2370 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #395: steps:2376 interval_time:0.49 train_time:3.98\u001b[00m\n",
            "\u001b[98m #396: steps:2382 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #397: steps:2388 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #398: steps:2394 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #399: steps:2400 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0002405: mean_reward:-0.030 mean_dist:0.091 var_dist:0.002\u001b[00m\n",
            "\u001b[98m #400: steps:2406 interval_time:3.56 train_time:3.98\u001b[00m\n",
            "\u001b[98m #401: steps:2412 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #402: steps:2418 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #403: steps:2424 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #404: steps:2430 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #405: steps:2436 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #406: steps:2442 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #407: steps:2448 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #408: steps:2454 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #409: steps:2460 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #410: steps:2466 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #411: steps:2472 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #412: steps:2478 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #413: steps:2484 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #414: steps:2490 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #415: steps:2496 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #416: steps:2502 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #417: steps:2508 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #418: steps:2514 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #419: steps:2520 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #420: steps:2526 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #421: steps:2532 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #422: steps:2538 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #423: steps:2544 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #424: steps:2550 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #425: steps:2556 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #426: steps:2562 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #427: steps:2568 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #428: steps:2574 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #429: steps:2580 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #430: steps:2586 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #431: steps:2592 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #432: steps:2598 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #433: steps:2604 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #434: steps:2610 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #435: steps:2616 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #436: steps:2622 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #437: steps:2628 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #438: steps:2634 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #439: steps:2640 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #440: steps:2646 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #441: steps:2652 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #442: steps:2658 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #443: steps:2664 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #444: steps:2670 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #445: steps:2676 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #446: steps:2682 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #447: steps:2688 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #448: steps:2694 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #449: steps:2700 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0002705: mean_reward:0.113 mean_dist:0.081 var_dist:0.001\u001b[00m\n",
            "\u001b[98m #450: steps:2706 interval_time:3.56 train_time:3.97\u001b[00m\n",
            "\u001b[98m #451: steps:2712 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #452: steps:2718 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #453: steps:2724 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #454: steps:2730 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #455: steps:2736 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #456: steps:2742 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #457: steps:2748 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #458: steps:2754 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #459: steps:2760 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #460: steps:2766 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #461: steps:2772 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #462: steps:2778 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #463: steps:2784 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #464: steps:2790 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #465: steps:2796 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #466: steps:2802 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #467: steps:2808 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #468: steps:2814 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #469: steps:2820 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #470: steps:2826 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #471: steps:2832 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #472: steps:2838 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #473: steps:2844 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #474: steps:2850 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #475: steps:2856 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #476: steps:2862 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #477: steps:2868 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #478: steps:2874 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #479: steps:2880 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #480: steps:2886 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #481: steps:2892 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #482: steps:2898 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #483: steps:2904 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #484: steps:2910 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #485: steps:2916 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #486: steps:2922 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #487: steps:2928 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #488: steps:2934 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #489: steps:2940 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #490: steps:2946 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #491: steps:2952 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #492: steps:2958 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #493: steps:2964 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #494: steps:2970 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #495: steps:2976 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #496: steps:2982 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #497: steps:2988 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #498: steps:2994 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #499: steps:3000 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0003005: mean_reward:-2.670 mean_dist:0.300 var_dist:0.001\u001b[00m\n",
            "\u001b[98m #500: steps:3006 interval_time:3.64 train_time:3.96\u001b[00m\n",
            "\u001b[98m #501: steps:3012 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #502: steps:3018 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #503: steps:3024 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #504: steps:3030 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #505: steps:3036 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #506: steps:3042 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #507: steps:3048 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #508: steps:3054 interval_time:0.48 train_time:3.96\u001b[00m\n",
            "\u001b[98m #509: steps:3060 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #510: steps:3066 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #511: steps:3072 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #512: steps:3078 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #513: steps:3084 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #514: steps:3090 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #515: steps:3096 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #516: steps:3102 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #517: steps:3108 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #518: steps:3114 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #519: steps:3120 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #520: steps:3126 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #521: steps:3132 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #522: steps:3138 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #523: steps:3144 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #524: steps:3150 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #525: steps:3156 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #526: steps:3162 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #527: steps:3168 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #528: steps:3174 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #529: steps:3180 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #530: steps:3186 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #531: steps:3192 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #532: steps:3198 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #533: steps:3204 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #534: steps:3210 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #535: steps:3216 interval_time:0.48 train_time:4.02\u001b[00m\n",
            "\u001b[98m #536: steps:3222 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #537: steps:3228 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #538: steps:3234 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #539: steps:3240 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #540: steps:3246 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #541: steps:3252 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #542: steps:3258 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #543: steps:3264 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #544: steps:3270 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #545: steps:3276 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #546: steps:3282 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #547: steps:3288 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #548: steps:3294 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #549: steps:3300 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[91m Step_0003305: mean_reward:-2.543 mean_dist:0.279 var_dist:0.001\u001b[00m\n",
            "\u001b[98m #550: steps:3306 interval_time:3.52 train_time:3.99\u001b[00m\n",
            "\u001b[98m #551: steps:3312 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #552: steps:3318 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #553: steps:3324 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #554: steps:3330 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #555: steps:3336 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #556: steps:3342 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #557: steps:3348 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #558: steps:3354 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #559: steps:3360 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #560: steps:3366 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #561: steps:3372 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #562: steps:3378 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #563: steps:3384 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #564: steps:3390 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #565: steps:3396 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #566: steps:3402 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #567: steps:3408 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #568: steps:3414 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #569: steps:3420 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #570: steps:3426 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #571: steps:3432 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #572: steps:3438 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #573: steps:3444 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #574: steps:3450 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #575: steps:3456 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #576: steps:3462 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #577: steps:3468 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #578: steps:3474 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #579: steps:3480 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #580: steps:3486 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #581: steps:3492 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #582: steps:3498 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #583: steps:3504 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #584: steps:3510 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #585: steps:3516 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #586: steps:3522 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #587: steps:3528 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #588: steps:3534 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #589: steps:3540 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #590: steps:3546 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #591: steps:3552 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #592: steps:3558 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #593: steps:3564 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #594: steps:3570 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #595: steps:3576 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #596: steps:3582 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #597: steps:3588 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #598: steps:3594 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #599: steps:3600 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0003605: mean_reward:0.422 mean_dist:0.053 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #600: steps:3606 interval_time:3.37 train_time:3.98\u001b[00m\n",
            "\u001b[98m #601: steps:3612 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #602: steps:3618 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #603: steps:3624 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #604: steps:3630 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #605: steps:3636 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #606: steps:3642 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #607: steps:3648 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #608: steps:3654 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #609: steps:3660 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #610: steps:3666 interval_time:0.49 train_time:3.98\u001b[00m\n",
            "\u001b[98m #611: steps:3672 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #612: steps:3678 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #613: steps:3684 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #614: steps:3690 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #615: steps:3696 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #616: steps:3702 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #617: steps:3708 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #618: steps:3714 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #619: steps:3720 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #620: steps:3726 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #621: steps:3732 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #622: steps:3738 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #623: steps:3744 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #624: steps:3750 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #625: steps:3756 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #626: steps:3762 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #627: steps:3768 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #628: steps:3774 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #629: steps:3780 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #630: steps:3786 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #631: steps:3792 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #632: steps:3798 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #633: steps:3804 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #634: steps:3810 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #635: steps:3816 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #636: steps:3822 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #637: steps:3828 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #638: steps:3834 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #639: steps:3840 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #640: steps:3846 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #641: steps:3852 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #642: steps:3858 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #643: steps:3864 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #644: steps:3870 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #645: steps:3876 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #646: steps:3882 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #647: steps:3888 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #648: steps:3894 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #649: steps:3900 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0003905: mean_reward:0.588 mean_dist:0.039 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #650: steps:3906 interval_time:3.44 train_time:3.98\u001b[00m\n",
            "\u001b[98m #651: steps:3912 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #652: steps:3918 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #653: steps:3924 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #654: steps:3930 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #655: steps:3936 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #656: steps:3942 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #657: steps:3948 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #658: steps:3954 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #659: steps:3960 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #660: steps:3966 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #661: steps:3972 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #662: steps:3978 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #663: steps:3984 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #664: steps:3990 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #665: steps:3996 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #666: steps:4002 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #667: steps:4008 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #668: steps:4014 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #669: steps:4020 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #670: steps:4026 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #671: steps:4032 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #672: steps:4038 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #673: steps:4044 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #674: steps:4050 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #675: steps:4056 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #676: steps:4062 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #677: steps:4068 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #678: steps:4074 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #679: steps:4080 interval_time:0.48 train_time:4.04\u001b[00m\n",
            "\u001b[98m #680: steps:4086 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #681: steps:4092 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #682: steps:4098 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #683: steps:4104 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #684: steps:4110 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #685: steps:4116 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #686: steps:4122 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #687: steps:4128 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #688: steps:4134 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #689: steps:4140 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #690: steps:4146 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #691: steps:4152 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #692: steps:4158 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #693: steps:4164 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #694: steps:4170 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #695: steps:4176 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #696: steps:4182 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #697: steps:4188 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #698: steps:4194 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #699: steps:4200 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[91m Step_0004205: mean_reward:0.652 mean_dist:0.032 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #700: steps:4206 interval_time:3.39 train_time:3.96\u001b[00m\n",
            "\u001b[98m #701: steps:4212 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #702: steps:4218 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #703: steps:4224 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #704: steps:4230 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #705: steps:4236 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #706: steps:4242 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #707: steps:4248 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #708: steps:4254 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #709: steps:4260 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #710: steps:4266 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #711: steps:4272 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #712: steps:4278 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #713: steps:4284 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #714: steps:4290 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #715: steps:4296 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #716: steps:4302 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #717: steps:4308 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #718: steps:4314 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #719: steps:4320 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #720: steps:4326 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #721: steps:4332 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #722: steps:4338 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #723: steps:4344 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #724: steps:4350 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #725: steps:4356 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #726: steps:4362 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #727: steps:4368 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #728: steps:4374 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #729: steps:4380 interval_time:0.47 train_time:4.05\u001b[00m\n",
            "\u001b[98m #730: steps:4386 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #731: steps:4392 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #732: steps:4398 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #733: steps:4404 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #734: steps:4410 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #735: steps:4416 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #736: steps:4422 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #737: steps:4428 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #738: steps:4434 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #739: steps:4440 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #740: steps:4446 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #741: steps:4452 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #742: steps:4458 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #743: steps:4464 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #744: steps:4470 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #745: steps:4476 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #746: steps:4482 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #747: steps:4488 interval_time:0.47 train_time:4.01\u001b[00m\n",
            "\u001b[98m #748: steps:4494 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #749: steps:4500 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[91m Step_0004505: mean_reward:0.696 mean_dist:0.028 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #750: steps:4506 interval_time:3.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #751: steps:4512 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #752: steps:4518 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #753: steps:4524 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #754: steps:4530 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #755: steps:4536 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #756: steps:4542 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #757: steps:4548 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #758: steps:4554 interval_time:0.51 train_time:3.97\u001b[00m\n",
            "\u001b[98m #759: steps:4560 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #760: steps:4566 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #761: steps:4572 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #762: steps:4578 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #763: steps:4584 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #764: steps:4590 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #765: steps:4596 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #766: steps:4602 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #767: steps:4608 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #768: steps:4614 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #769: steps:4620 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #770: steps:4626 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #771: steps:4632 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #772: steps:4638 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #773: steps:4644 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #774: steps:4650 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #775: steps:4656 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #776: steps:4662 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #777: steps:4668 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #778: steps:4674 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #779: steps:4680 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #780: steps:4686 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #781: steps:4692 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #782: steps:4698 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #783: steps:4704 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #784: steps:4710 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #785: steps:4716 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #786: steps:4722 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #787: steps:4728 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #788: steps:4734 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #789: steps:4740 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #790: steps:4746 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #791: steps:4752 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #792: steps:4758 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #793: steps:4764 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #794: steps:4770 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #795: steps:4776 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #796: steps:4782 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #797: steps:4788 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #798: steps:4794 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #799: steps:4800 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0004805: mean_reward:0.733 mean_dist:0.025 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #800: steps:4806 interval_time:3.44 train_time:3.98\u001b[00m\n",
            "\u001b[98m #801: steps:4812 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #802: steps:4818 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #803: steps:4824 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #804: steps:4830 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #805: steps:4836 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #806: steps:4842 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #807: steps:4848 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #808: steps:4854 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #809: steps:4860 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #810: steps:4866 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #811: steps:4872 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #812: steps:4878 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #813: steps:4884 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #814: steps:4890 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #815: steps:4896 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #816: steps:4902 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #817: steps:4908 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #818: steps:4914 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #819: steps:4920 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #820: steps:4926 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #821: steps:4932 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #822: steps:4938 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #823: steps:4944 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #824: steps:4950 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #825: steps:4956 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #826: steps:4962 interval_time:0.49 train_time:3.99\u001b[00m\n",
            "\u001b[98m #827: steps:4968 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #828: steps:4974 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #829: steps:4980 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #830: steps:4986 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #831: steps:4992 interval_time:0.49 train_time:3.98\u001b[00m\n",
            "\u001b[98m #832: steps:4998 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #833: steps:5004 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #834: steps:5010 interval_time:0.49 train_time:3.99\u001b[00m\n",
            "\u001b[98m #835: steps:5016 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #836: steps:5022 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #837: steps:5028 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #838: steps:5034 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #839: steps:5040 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #840: steps:5046 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #841: steps:5052 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #842: steps:5058 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #843: steps:5064 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #844: steps:5070 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #845: steps:5076 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #846: steps:5082 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #847: steps:5088 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #848: steps:5094 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #849: steps:5100 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0005105: mean_reward:0.765 mean_dist:0.022 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #850: steps:5106 interval_time:3.49 train_time:3.98\u001b[00m\n",
            "\u001b[98m #851: steps:5112 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #852: steps:5118 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #853: steps:5124 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #854: steps:5130 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #855: steps:5136 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #856: steps:5142 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #857: steps:5148 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #858: steps:5154 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #859: steps:5160 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #860: steps:5166 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #861: steps:5172 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #862: steps:5178 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #863: steps:5184 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #864: steps:5190 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #865: steps:5196 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #866: steps:5202 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #867: steps:5208 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #868: steps:5214 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #869: steps:5220 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #870: steps:5226 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #871: steps:5232 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #872: steps:5238 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #873: steps:5244 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #874: steps:5250 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #875: steps:5256 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #876: steps:5262 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #877: steps:5268 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #878: steps:5274 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #879: steps:5280 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #880: steps:5286 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #881: steps:5292 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #882: steps:5298 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #883: steps:5304 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #884: steps:5310 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #885: steps:5316 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #886: steps:5322 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #887: steps:5328 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #888: steps:5334 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #889: steps:5340 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #890: steps:5346 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #891: steps:5352 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #892: steps:5358 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #893: steps:5364 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #894: steps:5370 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #895: steps:5376 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #896: steps:5382 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #897: steps:5388 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #898: steps:5394 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #899: steps:5400 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0005405: mean_reward:0.789 mean_dist:0.020 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #900: steps:5406 interval_time:3.45 train_time:3.98\u001b[00m\n",
            "\u001b[98m #901: steps:5412 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #902: steps:5418 interval_time:0.49 train_time:3.98\u001b[00m\n",
            "\u001b[98m #903: steps:5424 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #904: steps:5430 interval_time:0.48 train_time:3.96\u001b[00m\n",
            "\u001b[98m #905: steps:5436 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #906: steps:5442 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #907: steps:5448 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #908: steps:5454 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #909: steps:5460 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #910: steps:5466 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #911: steps:5472 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #912: steps:5478 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #913: steps:5484 interval_time:0.47 train_time:4.01\u001b[00m\n",
            "\u001b[98m #914: steps:5490 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #915: steps:5496 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #916: steps:5502 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #917: steps:5508 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #918: steps:5514 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #919: steps:5520 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #920: steps:5526 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #921: steps:5532 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #922: steps:5538 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #923: steps:5544 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #924: steps:5550 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #925: steps:5556 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #926: steps:5562 interval_time:0.48 train_time:3.96\u001b[00m\n",
            "\u001b[98m #927: steps:5568 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #928: steps:5574 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #929: steps:5580 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #930: steps:5586 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #931: steps:5592 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #932: steps:5598 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #933: steps:5604 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #934: steps:5610 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #935: steps:5616 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #936: steps:5622 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #937: steps:5628 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #938: steps:5634 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #939: steps:5640 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #940: steps:5646 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #941: steps:5652 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #942: steps:5658 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #943: steps:5664 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #944: steps:5670 interval_time:0.49 train_time:3.98\u001b[00m\n",
            "\u001b[98m #945: steps:5676 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #946: steps:5682 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #947: steps:5688 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #948: steps:5694 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #949: steps:5700 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[91m Step_0005705: mean_reward:0.809 mean_dist:0.018 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #950: steps:5706 interval_time:3.45 train_time:3.98\u001b[00m\n",
            "\u001b[98m #951: steps:5712 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #952: steps:5718 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #953: steps:5724 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #954: steps:5730 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #955: steps:5736 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #956: steps:5742 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #957: steps:5748 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #958: steps:5754 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #959: steps:5760 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #960: steps:5766 interval_time:0.48 train_time:4.02\u001b[00m\n",
            "\u001b[98m #961: steps:5772 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #962: steps:5778 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #963: steps:5784 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #964: steps:5790 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #965: steps:5796 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #966: steps:5802 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #967: steps:5808 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #968: steps:5814 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #969: steps:5820 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #970: steps:5826 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #971: steps:5832 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #972: steps:5838 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #973: steps:5844 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #974: steps:5850 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #975: steps:5856 interval_time:0.49 train_time:3.98\u001b[00m\n",
            "\u001b[98m #976: steps:5862 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #977: steps:5868 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #978: steps:5874 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #979: steps:5880 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #980: steps:5886 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #981: steps:5892 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #982: steps:5898 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #983: steps:5904 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #984: steps:5910 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #985: steps:5916 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #986: steps:5922 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #987: steps:5928 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #988: steps:5934 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #989: steps:5940 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #990: steps:5946 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #991: steps:5952 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #992: steps:5958 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #993: steps:5964 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #994: steps:5970 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #995: steps:5976 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #996: steps:5982 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #997: steps:5988 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #998: steps:5994 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #999: steps:6000 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0006005: mean_reward:0.814 mean_dist:0.017 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1000: steps:6006 interval_time:3.43 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1001: steps:6012 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1002: steps:6018 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1003: steps:6024 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1004: steps:6030 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1005: steps:6036 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1006: steps:6042 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1007: steps:6048 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1008: steps:6054 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1009: steps:6060 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1010: steps:6066 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1011: steps:6072 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1012: steps:6078 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1013: steps:6084 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1014: steps:6090 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1015: steps:6096 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1016: steps:6102 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1017: steps:6108 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1018: steps:6114 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1019: steps:6120 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1020: steps:6126 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1021: steps:6132 interval_time:0.47 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1022: steps:6138 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1023: steps:6144 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1024: steps:6150 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1025: steps:6156 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1026: steps:6162 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1027: steps:6168 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1028: steps:6174 interval_time:0.49 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1029: steps:6180 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1030: steps:6186 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1031: steps:6192 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1032: steps:6198 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1033: steps:6204 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1034: steps:6210 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1035: steps:6216 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1036: steps:6222 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1037: steps:6228 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1038: steps:6234 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1039: steps:6240 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1040: steps:6246 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1041: steps:6252 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1042: steps:6258 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1043: steps:6264 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1044: steps:6270 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1045: steps:6276 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1046: steps:6282 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1047: steps:6288 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1048: steps:6294 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1049: steps:6300 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0006305: mean_reward:0.824 mean_dist:0.016 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1050: steps:6306 interval_time:3.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1051: steps:6312 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1052: steps:6318 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1053: steps:6324 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1054: steps:6330 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1055: steps:6336 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1056: steps:6342 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1057: steps:6348 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1058: steps:6354 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1059: steps:6360 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1060: steps:6366 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1061: steps:6372 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1062: steps:6378 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1063: steps:6384 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1064: steps:6390 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1065: steps:6396 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1066: steps:6402 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1067: steps:6408 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1068: steps:6414 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1069: steps:6420 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1070: steps:6426 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1071: steps:6432 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1072: steps:6438 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1073: steps:6444 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1074: steps:6450 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1075: steps:6456 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1076: steps:6462 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1077: steps:6468 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1078: steps:6474 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1079: steps:6480 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1080: steps:6486 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1081: steps:6492 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1082: steps:6498 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1083: steps:6504 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1084: steps:6510 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1085: steps:6516 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1086: steps:6522 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1087: steps:6528 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1088: steps:6534 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1089: steps:6540 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1090: steps:6546 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1091: steps:6552 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1092: steps:6558 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1093: steps:6564 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1094: steps:6570 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1095: steps:6576 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1096: steps:6582 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1097: steps:6588 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1098: steps:6594 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1099: steps:6600 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0006605: mean_reward:0.833 mean_dist:0.016 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1100: steps:6606 interval_time:3.51 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1101: steps:6612 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1102: steps:6618 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1103: steps:6624 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1104: steps:6630 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1105: steps:6636 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1106: steps:6642 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1107: steps:6648 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1108: steps:6654 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1109: steps:6660 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1110: steps:6666 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1111: steps:6672 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1112: steps:6678 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1113: steps:6684 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1114: steps:6690 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1115: steps:6696 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1116: steps:6702 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1117: steps:6708 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1118: steps:6714 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1119: steps:6720 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1120: steps:6726 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1121: steps:6732 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1122: steps:6738 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1123: steps:6744 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1124: steps:6750 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1125: steps:6756 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1126: steps:6762 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1127: steps:6768 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1128: steps:6774 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1129: steps:6780 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1130: steps:6786 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1131: steps:6792 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1132: steps:6798 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1133: steps:6804 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1134: steps:6810 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1135: steps:6816 interval_time:0.47 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1136: steps:6822 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1137: steps:6828 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1138: steps:6834 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1139: steps:6840 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1140: steps:6846 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1141: steps:6852 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1142: steps:6858 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1143: steps:6864 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1144: steps:6870 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1145: steps:6876 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1146: steps:6882 interval_time:0.49 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1147: steps:6888 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1148: steps:6894 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1149: steps:6900 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0006905: mean_reward:0.848 mean_dist:0.014 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1150: steps:6906 interval_time:3.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1151: steps:6912 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1152: steps:6918 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1153: steps:6924 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1154: steps:6930 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1155: steps:6936 interval_time:0.48 train_time:4.02\u001b[00m\n",
            "\u001b[98m #1156: steps:6942 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1157: steps:6948 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1158: steps:6954 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1159: steps:6960 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1160: steps:6966 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1161: steps:6972 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1162: steps:6978 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1163: steps:6984 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1164: steps:6990 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1165: steps:6996 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1166: steps:7002 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1167: steps:7008 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1168: steps:7014 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1169: steps:7020 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1170: steps:7026 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1171: steps:7032 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1172: steps:7038 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1173: steps:7044 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1174: steps:7050 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1175: steps:7056 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1176: steps:7062 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1177: steps:7068 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1178: steps:7074 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1179: steps:7080 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1180: steps:7086 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1181: steps:7092 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1182: steps:7098 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1183: steps:7104 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1184: steps:7110 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1185: steps:7116 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1186: steps:7122 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1187: steps:7128 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1188: steps:7134 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1189: steps:7140 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1190: steps:7146 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1191: steps:7152 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1192: steps:7158 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1193: steps:7164 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1194: steps:7170 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1195: steps:7176 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1196: steps:7182 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1197: steps:7188 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1198: steps:7194 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1199: steps:7200 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0007205: mean_reward:0.857 mean_dist:0.014 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1200: steps:7206 interval_time:3.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1201: steps:7212 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1202: steps:7218 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1203: steps:7224 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1204: steps:7230 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1205: steps:7236 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1206: steps:7242 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1207: steps:7248 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1208: steps:7254 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1209: steps:7260 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1210: steps:7266 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1211: steps:7272 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1212: steps:7278 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1213: steps:7284 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1214: steps:7290 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1215: steps:7296 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1216: steps:7302 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1217: steps:7308 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1218: steps:7314 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1219: steps:7320 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1220: steps:7326 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1221: steps:7332 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1222: steps:7338 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1223: steps:7344 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1224: steps:7350 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1225: steps:7356 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1226: steps:7362 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1227: steps:7368 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1228: steps:7374 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1229: steps:7380 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1230: steps:7386 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1231: steps:7392 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1232: steps:7398 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1233: steps:7404 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1234: steps:7410 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1235: steps:7416 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1236: steps:7422 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1237: steps:7428 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1238: steps:7434 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1239: steps:7440 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1240: steps:7446 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1241: steps:7452 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1242: steps:7458 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1243: steps:7464 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1244: steps:7470 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1245: steps:7476 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1246: steps:7482 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1247: steps:7488 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1248: steps:7494 interval_time:0.49 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1249: steps:7500 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0007505: mean_reward:0.853 mean_dist:0.014 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1250: steps:7506 interval_time:3.50 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1251: steps:7512 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1252: steps:7518 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1253: steps:7524 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1254: steps:7530 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1255: steps:7536 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1256: steps:7542 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1257: steps:7548 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1258: steps:7554 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1259: steps:7560 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1260: steps:7566 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1261: steps:7572 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1262: steps:7578 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1263: steps:7584 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1264: steps:7590 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1265: steps:7596 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1266: steps:7602 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1267: steps:7608 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1268: steps:7614 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1269: steps:7620 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1270: steps:7626 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1271: steps:7632 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1272: steps:7638 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1273: steps:7644 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1274: steps:7650 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1275: steps:7656 interval_time:0.48 train_time:4.02\u001b[00m\n",
            "\u001b[98m #1276: steps:7662 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1277: steps:7668 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1278: steps:7674 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1279: steps:7680 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1280: steps:7686 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1281: steps:7692 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1282: steps:7698 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1283: steps:7704 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1284: steps:7710 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1285: steps:7716 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1286: steps:7722 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1287: steps:7728 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1288: steps:7734 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1289: steps:7740 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1290: steps:7746 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1291: steps:7752 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1292: steps:7758 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1293: steps:7764 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1294: steps:7770 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1295: steps:7776 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1296: steps:7782 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1297: steps:7788 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1298: steps:7794 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1299: steps:7800 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0007805: mean_reward:0.851 mean_dist:0.014 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1300: steps:7806 interval_time:3.52 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1301: steps:7812 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1302: steps:7818 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1303: steps:7824 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1304: steps:7830 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1305: steps:7836 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1306: steps:7842 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1307: steps:7848 interval_time:0.48 train_time:4.02\u001b[00m\n",
            "\u001b[98m #1308: steps:7854 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1309: steps:7860 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1310: steps:7866 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1311: steps:7872 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1312: steps:7878 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1313: steps:7884 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1314: steps:7890 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1315: steps:7896 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1316: steps:7902 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1317: steps:7908 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1318: steps:7914 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1319: steps:7920 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1320: steps:7926 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1321: steps:7932 interval_time:0.47 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1322: steps:7938 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1323: steps:7944 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1324: steps:7950 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1325: steps:7956 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1326: steps:7962 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1327: steps:7968 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1328: steps:7974 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1329: steps:7980 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1330: steps:7986 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1331: steps:7992 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1332: steps:7998 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1333: steps:8004 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1334: steps:8010 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1335: steps:8016 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1336: steps:8022 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1337: steps:8028 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1338: steps:8034 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1339: steps:8040 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1340: steps:8046 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1341: steps:8052 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1342: steps:8058 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1343: steps:8064 interval_time:0.47 train_time:4.02\u001b[00m\n",
            "\u001b[98m #1344: steps:8070 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1345: steps:8076 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1346: steps:8082 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1347: steps:8088 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1348: steps:8094 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1349: steps:8100 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0008105: mean_reward:0.860 mean_dist:0.013 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1350: steps:8106 interval_time:3.53 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1351: steps:8112 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1352: steps:8118 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1353: steps:8124 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1354: steps:8130 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1355: steps:8136 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1356: steps:8142 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1357: steps:8148 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1358: steps:8154 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1359: steps:8160 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1360: steps:8166 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1361: steps:8172 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1362: steps:8178 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1363: steps:8184 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1364: steps:8190 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1365: steps:8196 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1366: steps:8202 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1367: steps:8208 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1368: steps:8214 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1369: steps:8220 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1370: steps:8226 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1371: steps:8232 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1372: steps:8238 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1373: steps:8244 interval_time:0.47 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1374: steps:8250 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1375: steps:8256 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1376: steps:8262 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1377: steps:8268 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1378: steps:8274 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1379: steps:8280 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1380: steps:8286 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1381: steps:8292 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1382: steps:8298 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1383: steps:8304 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1384: steps:8310 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1385: steps:8316 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1386: steps:8322 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1387: steps:8328 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1388: steps:8334 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1389: steps:8340 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1390: steps:8346 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1391: steps:8352 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1392: steps:8358 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1393: steps:8364 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1394: steps:8370 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1395: steps:8376 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1396: steps:8382 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1397: steps:8388 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1398: steps:8394 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1399: steps:8400 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0008405: mean_reward:0.863 mean_dist:0.013 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1400: steps:8406 interval_time:3.51 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1401: steps:8412 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1402: steps:8418 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1403: steps:8424 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1404: steps:8430 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1405: steps:8436 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1406: steps:8442 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1407: steps:8448 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1408: steps:8454 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1409: steps:8460 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1410: steps:8466 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1411: steps:8472 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1412: steps:8478 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1413: steps:8484 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1414: steps:8490 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1415: steps:8496 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1416: steps:8502 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1417: steps:8508 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1418: steps:8514 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1419: steps:8520 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1420: steps:8526 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1421: steps:8532 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1422: steps:8538 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1423: steps:8544 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1424: steps:8550 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1425: steps:8556 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1426: steps:8562 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1427: steps:8568 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1428: steps:8574 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1429: steps:8580 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1430: steps:8586 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1431: steps:8592 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1432: steps:8598 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1433: steps:8604 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1434: steps:8610 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1435: steps:8616 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1436: steps:8622 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1437: steps:8628 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1438: steps:8634 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1439: steps:8640 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1440: steps:8646 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1441: steps:8652 interval_time:0.47 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1442: steps:8658 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1443: steps:8664 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1444: steps:8670 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1445: steps:8676 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1446: steps:8682 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1447: steps:8688 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1448: steps:8694 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1449: steps:8700 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0008705: mean_reward:0.861 mean_dist:0.013 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1450: steps:8706 interval_time:3.55 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1451: steps:8712 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1452: steps:8718 interval_time:0.49 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1453: steps:8724 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1454: steps:8730 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1455: steps:8736 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1456: steps:8742 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1457: steps:8748 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1458: steps:8754 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1459: steps:8760 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1460: steps:8766 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1461: steps:8772 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1462: steps:8778 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1463: steps:8784 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1464: steps:8790 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1465: steps:8796 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1466: steps:8802 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1467: steps:8808 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1468: steps:8814 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1469: steps:8820 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1470: steps:8826 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1471: steps:8832 interval_time:0.47 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1472: steps:8838 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1473: steps:8844 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1474: steps:8850 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1475: steps:8856 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1476: steps:8862 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #1477: steps:8868 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1478: steps:8874 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1479: steps:8880 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1480: steps:8886 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1481: steps:8892 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1482: steps:8898 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1483: steps:8904 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1484: steps:8910 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1485: steps:8916 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1486: steps:8922 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1487: steps:8928 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1488: steps:8934 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1489: steps:8940 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1490: steps:8946 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1491: steps:8952 interval_time:0.47 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1492: steps:8958 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1493: steps:8964 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1494: steps:8970 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1495: steps:8976 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1496: steps:8982 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1497: steps:8988 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1498: steps:8994 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1499: steps:9000 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[91m Step_0009005: mean_reward:0.876 mean_dist:0.012 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1500: steps:9006 interval_time:3.59 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1501: steps:9012 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1502: steps:9018 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1503: steps:9024 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1504: steps:9030 interval_time:0.48 train_time:3.96\u001b[00m\n",
            "\u001b[98m #1505: steps:9036 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1506: steps:9042 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1507: steps:9048 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1508: steps:9054 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1509: steps:9060 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1510: steps:9066 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1511: steps:9072 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1512: steps:9078 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1513: steps:9084 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1514: steps:9090 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1515: steps:9096 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1516: steps:9102 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1517: steps:9108 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1518: steps:9114 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1519: steps:9120 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1520: steps:9126 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1521: steps:9132 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1522: steps:9138 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1523: steps:9144 interval_time:0.48 train_time:4.06\u001b[00m\n",
            "\u001b[98m #1524: steps:9150 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1525: steps:9156 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1526: steps:9162 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1527: steps:9168 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1528: steps:9174 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1529: steps:9180 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1530: steps:9186 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1531: steps:9192 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1532: steps:9198 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1533: steps:9204 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1534: steps:9210 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1535: steps:9216 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1536: steps:9222 interval_time:0.49 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1537: steps:9228 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1538: steps:9234 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1539: steps:9240 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1540: steps:9246 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1541: steps:9252 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1542: steps:9258 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1543: steps:9264 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1544: steps:9270 interval_time:0.49 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1545: steps:9276 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1546: steps:9282 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1547: steps:9288 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1548: steps:9294 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1549: steps:9300 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0009305: mean_reward:0.885 mean_dist:0.011 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1550: steps:9306 interval_time:3.56 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1551: steps:9312 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1552: steps:9318 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1553: steps:9324 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1554: steps:9330 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1555: steps:9336 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1556: steps:9342 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1557: steps:9348 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1558: steps:9354 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1559: steps:9360 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1560: steps:9366 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1561: steps:9372 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1562: steps:9378 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1563: steps:9384 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1564: steps:9390 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1565: steps:9396 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1566: steps:9402 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1567: steps:9408 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1568: steps:9414 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1569: steps:9420 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1570: steps:9426 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1571: steps:9432 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1572: steps:9438 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1573: steps:9444 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1574: steps:9450 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1575: steps:9456 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1576: steps:9462 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1577: steps:9468 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1578: steps:9474 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1579: steps:9480 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1580: steps:9486 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1581: steps:9492 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1582: steps:9498 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1583: steps:9504 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1584: steps:9510 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1585: steps:9516 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1586: steps:9522 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1587: steps:9528 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1588: steps:9534 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1589: steps:9540 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1590: steps:9546 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1591: steps:9552 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1592: steps:9558 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1593: steps:9564 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1594: steps:9570 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1595: steps:9576 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1596: steps:9582 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1597: steps:9588 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1598: steps:9594 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1599: steps:9600 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[91m Step_0009605: mean_reward:0.864 mean_dist:0.013 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1600: steps:9606 interval_time:3.56 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1601: steps:9612 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1602: steps:9618 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1603: steps:9624 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1604: steps:9630 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1605: steps:9636 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1606: steps:9642 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1607: steps:9648 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1608: steps:9654 interval_time:0.48 train_time:3.96\u001b[00m\n",
            "\u001b[98m #1609: steps:9660 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1610: steps:9666 interval_time:0.47 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1611: steps:9672 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1612: steps:9678 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1613: steps:9684 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1614: steps:9690 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1615: steps:9696 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1616: steps:9702 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1617: steps:9708 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1618: steps:9714 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1619: steps:9720 interval_time:0.47 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1620: steps:9726 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1621: steps:9732 interval_time:0.47 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1622: steps:9738 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1623: steps:9744 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1624: steps:9750 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1625: steps:9756 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1626: steps:9762 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1627: steps:9768 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1628: steps:9774 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1629: steps:9780 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1630: steps:9786 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1631: steps:9792 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1632: steps:9798 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1633: steps:9804 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1634: steps:9810 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #1635: steps:9816 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1636: steps:9822 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1637: steps:9828 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1638: steps:9834 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1639: steps:9840 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1640: steps:9846 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1641: steps:9852 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1642: steps:9858 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1643: steps:9864 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1644: steps:9870 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1645: steps:9876 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1646: steps:9882 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1647: steps:9888 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1648: steps:9894 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1649: steps:9900 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0009905: mean_reward:0.887 mean_dist:0.011 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1650: steps:9906 interval_time:3.58 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1651: steps:9912 interval_time:0.48 train_time:3.96\u001b[00m\n",
            "\u001b[98m #1652: steps:9918 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1653: steps:9924 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1654: steps:9930 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1655: steps:9936 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1656: steps:9942 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1657: steps:9948 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1658: steps:9954 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1659: steps:9960 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1660: steps:9966 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1661: steps:9972 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1662: steps:9978 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1663: steps:9984 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1664: steps:9990 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1665: steps:9996 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1666: steps:10002 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1667: steps:10008 interval_time:0.51 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1668: steps:10014 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1669: steps:10020 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1670: steps:10026 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1671: steps:10032 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1672: steps:10038 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1673: steps:10044 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1674: steps:10050 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1675: steps:10056 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1676: steps:10062 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1677: steps:10068 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1678: steps:10074 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1679: steps:10080 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1680: steps:10086 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1681: steps:10092 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1682: steps:10098 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1683: steps:10104 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1684: steps:10110 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1685: steps:10116 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1686: steps:10122 interval_time:0.47 train_time:4.16\u001b[00m\n",
            "\u001b[98m #1687: steps:10128 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1688: steps:10134 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1689: steps:10140 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1690: steps:10146 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1691: steps:10152 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1692: steps:10158 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1693: steps:10164 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1694: steps:10170 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1695: steps:10176 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1696: steps:10182 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1697: steps:10188 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1698: steps:10194 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1699: steps:10200 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0010205: mean_reward:0.886 mean_dist:0.011 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1700: steps:10206 interval_time:3.54 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1701: steps:10212 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1702: steps:10218 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1703: steps:10224 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1704: steps:10230 interval_time:0.48 train_time:3.96\u001b[00m\n",
            "\u001b[98m #1705: steps:10236 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1706: steps:10242 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1707: steps:10248 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1708: steps:10254 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1709: steps:10260 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1710: steps:10266 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1711: steps:10272 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1712: steps:10278 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1713: steps:10284 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1714: steps:10290 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1715: steps:10296 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1716: steps:10302 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1717: steps:10308 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1718: steps:10314 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1719: steps:10320 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1720: steps:10326 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1721: steps:10332 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1722: steps:10338 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1723: steps:10344 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1724: steps:10350 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1725: steps:10356 interval_time:0.48 train_time:4.02\u001b[00m\n",
            "\u001b[98m #1726: steps:10362 interval_time:0.48 train_time:4.07\u001b[00m\n",
            "\u001b[98m #1727: steps:10368 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1728: steps:10374 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1729: steps:10380 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1730: steps:10386 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1731: steps:10392 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1732: steps:10398 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1733: steps:10404 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1734: steps:10410 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1735: steps:10416 interval_time:0.47 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1736: steps:10422 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1737: steps:10428 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1738: steps:10434 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1739: steps:10440 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1740: steps:10446 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1741: steps:10452 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1742: steps:10458 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1743: steps:10464 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1744: steps:10470 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1745: steps:10476 interval_time:0.47 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1746: steps:10482 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1747: steps:10488 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1748: steps:10494 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1749: steps:10500 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0010505: mean_reward:0.881 mean_dist:0.011 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1750: steps:10506 interval_time:3.54 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1751: steps:10512 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1752: steps:10518 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1753: steps:10524 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1754: steps:10530 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1755: steps:10536 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1756: steps:10542 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1757: steps:10548 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1758: steps:10554 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1759: steps:10560 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1760: steps:10566 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1761: steps:10572 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1762: steps:10578 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1763: steps:10584 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1764: steps:10590 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1765: steps:10596 interval_time:0.48 train_time:4.07\u001b[00m\n",
            "\u001b[98m #1766: steps:10602 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1767: steps:10608 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1768: steps:10614 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1769: steps:10620 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1770: steps:10626 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1771: steps:10632 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1772: steps:10638 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1773: steps:10644 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1774: steps:10650 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1775: steps:10656 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1776: steps:10662 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1777: steps:10668 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1778: steps:10674 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1779: steps:10680 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1780: steps:10686 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1781: steps:10692 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1782: steps:10698 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1783: steps:10704 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1784: steps:10710 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1785: steps:10716 interval_time:0.47 train_time:4.05\u001b[00m\n",
            "\u001b[98m #1786: steps:10722 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1787: steps:10728 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1788: steps:10734 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1789: steps:10740 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1790: steps:10746 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1791: steps:10752 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1792: steps:10758 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1793: steps:10764 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1794: steps:10770 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1795: steps:10776 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1796: steps:10782 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1797: steps:10788 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1798: steps:10794 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1799: steps:10800 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0010805: mean_reward:0.888 mean_dist:0.010 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1800: steps:10806 interval_time:3.53 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1801: steps:10812 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1802: steps:10818 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1803: steps:10824 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1804: steps:10830 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1805: steps:10836 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1806: steps:10842 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1807: steps:10848 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1808: steps:10854 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1809: steps:10860 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1810: steps:10866 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1811: steps:10872 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1812: steps:10878 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1813: steps:10884 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1814: steps:10890 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1815: steps:10896 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1816: steps:10902 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1817: steps:10908 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1818: steps:10914 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1819: steps:10920 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1820: steps:10926 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1821: steps:10932 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1822: steps:10938 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1823: steps:10944 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1824: steps:10950 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1825: steps:10956 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1826: steps:10962 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1827: steps:10968 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1828: steps:10974 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1829: steps:10980 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1830: steps:10986 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1831: steps:10992 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1832: steps:10998 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1833: steps:11004 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1834: steps:11010 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1835: steps:11016 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1836: steps:11022 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1837: steps:11028 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1838: steps:11034 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1839: steps:11040 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1840: steps:11046 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1841: steps:11052 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1842: steps:11058 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1843: steps:11064 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1844: steps:11070 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1845: steps:11076 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1846: steps:11082 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1847: steps:11088 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1848: steps:11094 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1849: steps:11100 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0011105: mean_reward:0.887 mean_dist:0.010 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1850: steps:11106 interval_time:3.51 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1851: steps:11112 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1852: steps:11118 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1853: steps:11124 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1854: steps:11130 interval_time:0.49 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1855: steps:11136 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1856: steps:11142 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1857: steps:11148 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1858: steps:11154 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1859: steps:11160 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1860: steps:11166 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1861: steps:11172 interval_time:0.48 train_time:4.09\u001b[00m\n",
            "\u001b[98m #1862: steps:11178 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1863: steps:11184 interval_time:0.47 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1864: steps:11190 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1865: steps:11196 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1866: steps:11202 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1867: steps:11208 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1868: steps:11214 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1869: steps:11220 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1870: steps:11226 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1871: steps:11232 interval_time:0.47 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1872: steps:11238 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1873: steps:11244 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1874: steps:11250 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1875: steps:11256 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1876: steps:11262 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1877: steps:11268 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1878: steps:11274 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1879: steps:11280 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1880: steps:11286 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1881: steps:11292 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1882: steps:11298 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1883: steps:11304 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1884: steps:11310 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1885: steps:11316 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1886: steps:11322 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1887: steps:11328 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1888: steps:11334 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1889: steps:11340 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1890: steps:11346 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1891: steps:11352 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1892: steps:11358 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1893: steps:11364 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1894: steps:11370 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1895: steps:11376 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1896: steps:11382 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1897: steps:11388 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1898: steps:11394 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1899: steps:11400 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0011405: mean_reward:0.887 mean_dist:0.011 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1900: steps:11406 interval_time:3.50 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1901: steps:11412 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1902: steps:11418 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1903: steps:11424 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1904: steps:11430 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1905: steps:11436 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1906: steps:11442 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1907: steps:11448 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1908: steps:11454 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1909: steps:11460 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1910: steps:11466 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1911: steps:11472 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1912: steps:11478 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1913: steps:11484 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1914: steps:11490 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1915: steps:11496 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1916: steps:11502 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1917: steps:11508 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1918: steps:11514 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1919: steps:11520 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1920: steps:11526 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1921: steps:11532 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1922: steps:11538 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1923: steps:11544 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1924: steps:11550 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1925: steps:11556 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1926: steps:11562 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1927: steps:11568 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1928: steps:11574 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1929: steps:11580 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1930: steps:11586 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1931: steps:11592 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1932: steps:11598 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1933: steps:11604 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1934: steps:11610 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1935: steps:11616 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1936: steps:11622 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1937: steps:11628 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1938: steps:11634 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1939: steps:11640 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1940: steps:11646 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1941: steps:11652 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1942: steps:11658 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1943: steps:11664 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1944: steps:11670 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1945: steps:11676 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1946: steps:11682 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1947: steps:11688 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1948: steps:11694 interval_time:0.48 train_time:4.05\u001b[00m\n",
            "\u001b[98m #1949: steps:11700 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0011705: mean_reward:0.892 mean_dist:0.010 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #1950: steps:11706 interval_time:3.58 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1951: steps:11712 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1952: steps:11718 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1953: steps:11724 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1954: steps:11730 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1955: steps:11736 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1956: steps:11742 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1957: steps:11748 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1958: steps:11754 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1959: steps:11760 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1960: steps:11766 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1961: steps:11772 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1962: steps:11778 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1963: steps:11784 interval_time:0.48 train_time:4.02\u001b[00m\n",
            "\u001b[98m #1964: steps:11790 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1965: steps:11796 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1966: steps:11802 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1967: steps:11808 interval_time:0.50 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1968: steps:11814 interval_time:0.54 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1969: steps:11820 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1970: steps:11826 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1971: steps:11832 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1972: steps:11838 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #1973: steps:11844 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1974: steps:11850 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1975: steps:11856 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1976: steps:11862 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1977: steps:11868 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1978: steps:11874 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1979: steps:11880 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1980: steps:11886 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1981: steps:11892 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1982: steps:11898 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1983: steps:11904 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1984: steps:11910 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1985: steps:11916 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1986: steps:11922 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1987: steps:11928 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #1988: steps:11934 interval_time:0.54 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1989: steps:11940 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1990: steps:11946 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1991: steps:11952 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1992: steps:11958 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1993: steps:11964 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1994: steps:11970 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #1995: steps:11976 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1996: steps:11982 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1997: steps:11988 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #1998: steps:11994 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #1999: steps:12000 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0012005: mean_reward:0.894 mean_dist:0.010 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #2000: steps:12006 interval_time:3.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2001: steps:12012 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2002: steps:12018 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2003: steps:12024 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2004: steps:12030 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2005: steps:12036 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2006: steps:12042 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2007: steps:12048 interval_time:0.47 train_time:4.06\u001b[00m\n",
            "\u001b[98m #2008: steps:12054 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2009: steps:12060 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2010: steps:12066 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2011: steps:12072 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2012: steps:12078 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2013: steps:12084 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2014: steps:12090 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2015: steps:12096 interval_time:0.47 train_time:4.01\u001b[00m\n",
            "\u001b[98m #2016: steps:12102 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2017: steps:12108 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2018: steps:12114 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2019: steps:12120 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2020: steps:12126 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2021: steps:12132 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2022: steps:12138 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2023: steps:12144 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2024: steps:12150 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2025: steps:12156 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2026: steps:12162 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2027: steps:12168 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2028: steps:12174 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2029: steps:12180 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2030: steps:12186 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2031: steps:12192 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2032: steps:12198 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2033: steps:12204 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2034: steps:12210 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2035: steps:12216 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2036: steps:12222 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2037: steps:12228 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2038: steps:12234 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2039: steps:12240 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2040: steps:12246 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2041: steps:12252 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2042: steps:12258 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2043: steps:12264 interval_time:0.48 train_time:4.11\u001b[00m\n",
            "\u001b[98m #2044: steps:12270 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2045: steps:12276 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2046: steps:12282 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2047: steps:12288 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2048: steps:12294 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2049: steps:12300 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0012305: mean_reward:0.902 mean_dist:0.009 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #2050: steps:12306 interval_time:3.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2051: steps:12312 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2052: steps:12318 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2053: steps:12324 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2054: steps:12330 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2055: steps:12336 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2056: steps:12342 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2057: steps:12348 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2058: steps:12354 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2059: steps:12360 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2060: steps:12366 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2061: steps:12372 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2062: steps:12378 interval_time:0.48 train_time:4.16\u001b[00m\n",
            "\u001b[98m #2063: steps:12384 interval_time:0.49 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2064: steps:12390 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2065: steps:12396 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2066: steps:12402 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2067: steps:12408 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2068: steps:12414 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2069: steps:12420 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2070: steps:12426 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2071: steps:12432 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2072: steps:12438 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2073: steps:12444 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2074: steps:12450 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2075: steps:12456 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2076: steps:12462 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2077: steps:12468 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2078: steps:12474 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2079: steps:12480 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2080: steps:12486 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2081: steps:12492 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2082: steps:12498 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2083: steps:12504 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2084: steps:12510 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2085: steps:12516 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2086: steps:12522 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2087: steps:12528 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2088: steps:12534 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2089: steps:12540 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2090: steps:12546 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #2091: steps:12552 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2092: steps:12558 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2093: steps:12564 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2094: steps:12570 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2095: steps:12576 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2096: steps:12582 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2097: steps:12588 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2098: steps:12594 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2099: steps:12600 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0012605: mean_reward:0.905 mean_dist:0.009 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #2100: steps:12606 interval_time:3.53 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2101: steps:12612 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2102: steps:12618 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2103: steps:12624 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2104: steps:12630 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2105: steps:12636 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2106: steps:12642 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2107: steps:12648 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2108: steps:12654 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2109: steps:12660 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2110: steps:12666 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2111: steps:12672 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2112: steps:12678 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2113: steps:12684 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2114: steps:12690 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2115: steps:12696 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2116: steps:12702 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2117: steps:12708 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2118: steps:12714 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2119: steps:12720 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2120: steps:12726 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2121: steps:12732 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2122: steps:12738 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2123: steps:12744 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2124: steps:12750 interval_time:0.47 train_time:3.96\u001b[00m\n",
            "\u001b[98m #2125: steps:12756 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2126: steps:12762 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2127: steps:12768 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2128: steps:12774 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2129: steps:12780 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2130: steps:12786 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2131: steps:12792 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2132: steps:12798 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2133: steps:12804 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2134: steps:12810 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2135: steps:12816 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2136: steps:12822 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2137: steps:12828 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2138: steps:12834 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2139: steps:12840 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2140: steps:12846 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2141: steps:12852 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2142: steps:12858 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2143: steps:12864 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2144: steps:12870 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2145: steps:12876 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2146: steps:12882 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2147: steps:12888 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2148: steps:12894 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2149: steps:12900 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0012905: mean_reward:0.908 mean_dist:0.009 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #2150: steps:12906 interval_time:3.54 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2151: steps:12912 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2152: steps:12918 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2153: steps:12924 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2154: steps:12930 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2155: steps:12936 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2156: steps:12942 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2157: steps:12948 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2158: steps:12954 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2159: steps:12960 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2160: steps:12966 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2161: steps:12972 interval_time:0.47 train_time:4.10\u001b[00m\n",
            "\u001b[98m #2162: steps:12978 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2163: steps:12984 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2164: steps:12990 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2165: steps:12996 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2166: steps:13002 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2167: steps:13008 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2168: steps:13014 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2169: steps:13020 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2170: steps:13026 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2171: steps:13032 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2172: steps:13038 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2173: steps:13044 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2174: steps:13050 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2175: steps:13056 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2176: steps:13062 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2177: steps:13068 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2178: steps:13074 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2179: steps:13080 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2180: steps:13086 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2181: steps:13092 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2182: steps:13098 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2183: steps:13104 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2184: steps:13110 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2185: steps:13116 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2186: steps:13122 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2187: steps:13128 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2188: steps:13134 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2189: steps:13140 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2190: steps:13146 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2191: steps:13152 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2192: steps:13158 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2193: steps:13164 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2194: steps:13170 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2195: steps:13176 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2196: steps:13182 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2197: steps:13188 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2198: steps:13194 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2199: steps:13200 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[91m Step_0013205: mean_reward:0.903 mean_dist:0.009 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #2200: steps:13206 interval_time:3.53 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2201: steps:13212 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2202: steps:13218 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2203: steps:13224 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2204: steps:13230 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2205: steps:13236 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2206: steps:13242 interval_time:0.48 train_time:3.96\u001b[00m\n",
            "\u001b[98m #2207: steps:13248 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2208: steps:13254 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2209: steps:13260 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2210: steps:13266 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2211: steps:13272 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2212: steps:13278 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2213: steps:13284 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2214: steps:13290 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2215: steps:13296 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2216: steps:13302 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2217: steps:13308 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2218: steps:13314 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2219: steps:13320 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2220: steps:13326 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2221: steps:13332 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2222: steps:13338 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2223: steps:13344 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2224: steps:13350 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2225: steps:13356 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2226: steps:13362 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2227: steps:13368 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2228: steps:13374 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2229: steps:13380 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2230: steps:13386 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2231: steps:13392 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2232: steps:13398 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2233: steps:13404 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2234: steps:13410 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2235: steps:13416 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2236: steps:13422 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2237: steps:13428 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2238: steps:13434 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2239: steps:13440 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2240: steps:13446 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2241: steps:13452 interval_time:0.48 train_time:4.06\u001b[00m\n",
            "\u001b[98m #2242: steps:13458 interval_time:0.55 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2243: steps:13464 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2244: steps:13470 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2245: steps:13476 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2246: steps:13482 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2247: steps:13488 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2248: steps:13494 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2249: steps:13500 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0013505: mean_reward:0.900 mean_dist:0.009 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #2250: steps:13506 interval_time:3.50 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2251: steps:13512 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2252: steps:13518 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2253: steps:13524 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2254: steps:13530 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2255: steps:13536 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2256: steps:13542 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2257: steps:13548 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2258: steps:13554 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2259: steps:13560 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2260: steps:13566 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2261: steps:13572 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2262: steps:13578 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2263: steps:13584 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2264: steps:13590 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2265: steps:13596 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2266: steps:13602 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2267: steps:13608 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2268: steps:13614 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2269: steps:13620 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2270: steps:13626 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2271: steps:13632 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2272: steps:13638 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2273: steps:13644 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2274: steps:13650 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2275: steps:13656 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2276: steps:13662 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2277: steps:13668 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2278: steps:13674 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2279: steps:13680 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2280: steps:13686 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2281: steps:13692 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2282: steps:13698 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2283: steps:13704 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2284: steps:13710 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2285: steps:13716 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2286: steps:13722 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2287: steps:13728 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2288: steps:13734 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2289: steps:13740 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2290: steps:13746 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2291: steps:13752 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2292: steps:13758 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2293: steps:13764 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2294: steps:13770 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2295: steps:13776 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2296: steps:13782 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2297: steps:13788 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2298: steps:13794 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2299: steps:13800 interval_time:0.48 train_time:4.11\u001b[00m\n",
            "\u001b[91m Step_0013805: mean_reward:0.910 mean_dist:0.008 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #2300: steps:13806 interval_time:3.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2301: steps:13812 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2302: steps:13818 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2303: steps:13824 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2304: steps:13830 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2305: steps:13836 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2306: steps:13842 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2307: steps:13848 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2308: steps:13854 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2309: steps:13860 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2310: steps:13866 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2311: steps:13872 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2312: steps:13878 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2313: steps:13884 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2314: steps:13890 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2315: steps:13896 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2316: steps:13902 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2317: steps:13908 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2318: steps:13914 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #2319: steps:13920 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2320: steps:13926 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2321: steps:13932 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2322: steps:13938 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2323: steps:13944 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2324: steps:13950 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2325: steps:13956 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2326: steps:13962 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2327: steps:13968 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2328: steps:13974 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2329: steps:13980 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2330: steps:13986 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2331: steps:13992 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #2332: steps:13998 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2333: steps:14004 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2334: steps:14010 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2335: steps:14016 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2336: steps:14022 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2337: steps:14028 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2338: steps:14034 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2339: steps:14040 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2340: steps:14046 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2341: steps:14052 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2342: steps:14058 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2343: steps:14064 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2344: steps:14070 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2345: steps:14076 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2346: steps:14082 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2347: steps:14088 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2348: steps:14094 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2349: steps:14100 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0014105: mean_reward:0.910 mean_dist:0.009 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #2350: steps:14106 interval_time:3.49 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2351: steps:14112 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2352: steps:14118 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2353: steps:14124 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2354: steps:14130 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2355: steps:14136 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2356: steps:14142 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2357: steps:14148 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2358: steps:14154 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2359: steps:14160 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2360: steps:14166 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2361: steps:14172 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2362: steps:14178 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2363: steps:14184 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2364: steps:14190 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2365: steps:14196 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2366: steps:14202 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2367: steps:14208 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2368: steps:14214 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2369: steps:14220 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2370: steps:14226 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2371: steps:14232 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2372: steps:14238 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2373: steps:14244 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2374: steps:14250 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2375: steps:14256 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2376: steps:14262 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2377: steps:14268 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2378: steps:14274 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2379: steps:14280 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2380: steps:14286 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2381: steps:14292 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2382: steps:14298 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2383: steps:14304 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2384: steps:14310 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2385: steps:14316 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2386: steps:14322 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2387: steps:14328 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2388: steps:14334 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2389: steps:14340 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2390: steps:14346 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2391: steps:14352 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2392: steps:14358 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2393: steps:14364 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2394: steps:14370 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2395: steps:14376 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2396: steps:14382 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2397: steps:14388 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2398: steps:14394 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2399: steps:14400 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[91m Step_0014405: mean_reward:0.915 mean_dist:0.008 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #2400: steps:14406 interval_time:3.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2401: steps:14412 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2402: steps:14418 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2403: steps:14424 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2404: steps:14430 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2405: steps:14436 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2406: steps:14442 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2407: steps:14448 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2408: steps:14454 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2409: steps:14460 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2410: steps:14466 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2411: steps:14472 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2412: steps:14478 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2413: steps:14484 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2414: steps:14490 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2415: steps:14496 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2416: steps:14502 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2417: steps:14508 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2418: steps:14514 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2419: steps:14520 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2420: steps:14526 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2421: steps:14532 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2422: steps:14538 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2423: steps:14544 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2424: steps:14550 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2425: steps:14556 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2426: steps:14562 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2427: steps:14568 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2428: steps:14574 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2429: steps:14580 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2430: steps:14586 interval_time:0.48 train_time:4.01\u001b[00m\n",
            "\u001b[98m #2431: steps:14592 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2432: steps:14598 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2433: steps:14604 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2434: steps:14610 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2435: steps:14616 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2436: steps:14622 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2437: steps:14628 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2438: steps:14634 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2439: steps:14640 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2440: steps:14646 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2441: steps:14652 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2442: steps:14658 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2443: steps:14664 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2444: steps:14670 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2445: steps:14676 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2446: steps:14682 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2447: steps:14688 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2448: steps:14694 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2449: steps:14700 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[91m Step_0014705: mean_reward:0.915 mean_dist:0.008 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #2450: steps:14706 interval_time:3.55 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2451: steps:14712 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2452: steps:14718 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2453: steps:14724 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2454: steps:14730 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2455: steps:14736 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2456: steps:14742 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2457: steps:14748 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2458: steps:14754 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2459: steps:14760 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2460: steps:14766 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2461: steps:14772 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2462: steps:14778 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2463: steps:14784 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2464: steps:14790 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2465: steps:14796 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2466: steps:14802 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2467: steps:14808 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2468: steps:14814 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2469: steps:14820 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2470: steps:14826 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2471: steps:14832 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2472: steps:14838 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2473: steps:14844 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2474: steps:14850 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2475: steps:14856 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2476: steps:14862 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2477: steps:14868 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2478: steps:14874 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2479: steps:14880 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2480: steps:14886 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2481: steps:14892 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2482: steps:14898 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2483: steps:14904 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2484: steps:14910 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2485: steps:14916 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2486: steps:14922 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2487: steps:14928 interval_time:0.47 train_time:4.02\u001b[00m\n",
            "\u001b[98m #2488: steps:14934 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2489: steps:14940 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2490: steps:14946 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2491: steps:14952 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2492: steps:14958 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2493: steps:14964 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2494: steps:14970 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2495: steps:14976 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2496: steps:14982 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2497: steps:14988 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2498: steps:14994 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2499: steps:15000 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[91m Step_0015005: mean_reward:0.916 mean_dist:0.008 var_dist:0.000\u001b[00m\n",
            "\u001b[98m #2500: steps:15006 interval_time:3.55 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2501: steps:15012 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2502: steps:15018 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2503: steps:15024 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2504: steps:15030 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2505: steps:15036 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2506: steps:15042 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2507: steps:15048 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2508: steps:15054 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2509: steps:15060 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2510: steps:15066 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2511: steps:15072 interval_time:0.47 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2512: steps:15078 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2513: steps:15084 interval_time:0.48 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2514: steps:15090 interval_time:0.49 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2515: steps:15096 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2516: steps:15102 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2517: steps:15108 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2518: steps:15114 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2519: steps:15120 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2520: steps:15126 interval_time:0.49 train_time:4.00\u001b[00m\n",
            "\u001b[98m #2521: steps:15132 interval_time:0.50 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2522: steps:15138 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2523: steps:15144 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2524: steps:15150 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2525: steps:15156 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2526: steps:15162 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2527: steps:15168 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2528: steps:15174 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2529: steps:15180 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2530: steps:15186 interval_time:0.48 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2531: steps:15192 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2532: steps:15198 interval_time:0.47 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2533: steps:15204 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2534: steps:15210 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2535: steps:15216 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2536: steps:15222 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2537: steps:15228 interval_time:0.47 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2538: steps:15234 interval_time:0.47 train_time:3.97\u001b[00m\n",
            "\u001b[98m #2539: steps:15240 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2540: steps:15246 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "\u001b[98m #2541: steps:15252 interval_time:0.48 train_time:3.99\u001b[00m\n",
            "\u001b[98m #2542: steps:15258 interval_time:0.48 train_time:3.98\u001b[00m\n",
            "Traceback (most recent call last):\n",
            "  File \"baseline/train.py\", line 114, in <module>\n",
            "    train(agent, fenv, evaluate)\n",
            "  File \"baseline/train.py\", line 62, in train\n",
            "    Q, value_loss = agent.update_policy(lr)\n",
            "  File \"/content/LearningToPaint/baseline/DRL/ddpg.py\", line 128, in update_policy\n",
            "    self.update_gan(next_state)\n",
            "  File \"/content/LearningToPaint/baseline/DRL/ddpg.py\", line 90, in update_gan\n",
            "    fake, real, penal = update(canvas.float() / 255, gt.float() / 255)\n",
            "  File \"/content/LearningToPaint/baseline/DRL/wgan.py\", line 123, in update\n",
            "    gradient_penalty = cal_gradient_penalty(netD, real, fake, real.shape[0])\n",
            "  File \"/content/LearningToPaint/baseline/DRL/wgan.py\", line 89, in cal_gradient_penalty\n",
            "    alpha = alpha.to(device)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9q0A5XtgCGL"
      },
      "source": [
        "!rm /content/train_log/LearningToPaint/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08Owebr2gCgF",
        "outputId": "4fc0df4c-0aca-471e-b238-9fb5f347e2a9"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AijbF7ypgwpv"
      },
      "source": [
        "!mkdir ../../gdrive/MyDrive/RL/new_ppo_20000_35"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InXQmG2DhPe2"
      },
      "source": [
        "!cp  -r /content/content/LearningToPaint/model/Paint-run25 ../../gdrive/MyDrive/RL/ppo_20000_25/\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVWGldWk_3Zs",
        "outputId": "d99867c0-fa28-474e-fa5b-4484145799fc"
      },
      "source": [
        "!ls ../../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1iHaIlhNSsIGNvz3eKizXjK21FIHmqL-o  content  gdrive  sample_data  save.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYScKo0X3iBA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBfz4t97hlnG",
        "outputId": "6402a1b7-01c1-4dd2-ffe3-d3b5659f0cc8"
      },
      "source": [
        "ls ../gdrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '../gdrive': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUSFdzq0iBwc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tb4xCmpJkdH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}